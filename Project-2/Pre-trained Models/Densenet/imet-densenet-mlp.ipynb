{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Problem description\n\nIn this kernel, we are going to use Densenet121 pretrained model with Pytorch.","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Libraries","metadata":{}},{"cell_type":"code","source":"import gc\nimport os\nimport sys\nimport time\nimport random\nimport logging\nimport datetime as dt\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.utils.data as data\nimport torch.nn.functional as F\nimport torchvision as vision\n\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\n\nfrom pathlib import Path\nfrom PIL import Image\nfrom contextlib import contextmanager\n\nfrom joblib import Parallel, delayed\nfrom tqdm import tqdm\nfrom fastprogress import master_bar, progress_bar\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import fbeta_score\n\ntorch.multiprocessing.set_start_method(\"spawn\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-06T19:58:46.618013Z","iopub.execute_input":"2022-12-06T19:58:46.618227Z","iopub.status.idle":"2022-12-06T19:58:48.330625Z","shell.execute_reply.started":"2022-12-06T19:58:46.618182Z","shell.execute_reply":"2022-12-06T19:58:48.329583Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"## Utilities","metadata":{}},{"cell_type":"code","source":"@contextmanager\ndef timer(name=\"Main\", logger=None):\n    t0 = time.time()\n    yield\n    msg = f\"[{name}] done in {time.time() - t0} s\"\n    if logger is not None:\n        logger.info(msg)\n    else:\n        print(msg)\n        \n\ndef get_logger(name=\"Main\", tag=\"exp\", log_dir=\"log/\"):\n    log_path = Path(log_dir)\n    path = log_path / tag\n    path.mkdir(exist_ok=True, parents=True)\n\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    fh = logging.FileHandler(\n        path / (dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\") + \".log\"))\n    sh = logging.StreamHandler(sys.stdout)\n    formatter = logging.Formatter(\n        \"%(asctime)s %(name)s %(levelname)s %(message)s\")\n\n    fh.setFormatter(formatter)\n    sh.setFormatter(formatter)\n    logger.addHandler(fh)\n    logger.addHandler(sh)\n    return logger\n\n\ndef seed_torch(seed=1029):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-12-06T19:58:48.332182Z","iopub.execute_input":"2022-12-06T19:58:48.332732Z","iopub.status.idle":"2022-12-06T19:58:48.341887Z","shell.execute_reply.started":"2022-12-06T19:58:48.332678Z","shell.execute_reply":"2022-12-06T19:58:48.341106Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"logger = get_logger(name=\"Main\", tag=\"Pytorch-VGG16\")","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:58:48.343214Z","iopub.execute_input":"2022-12-06T19:58:48.343810Z","iopub.status.idle":"2022-12-06T19:58:48.351158Z","shell.execute_reply.started":"2022-12-06T19:58:48.343724Z","shell.execute_reply":"2022-12-06T19:58:48.350282Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"!ls ../input/imet-2019-fgvc6/","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:58:48.353398Z","iopub.execute_input":"2022-12-06T19:58:48.353877Z","iopub.status.idle":"2022-12-06T19:58:49.442870Z","shell.execute_reply.started":"2022-12-06T19:58:48.353827Z","shell.execute_reply":"2022-12-06T19:58:49.441999Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"labels.csv  sample_submission.csv  test  train\ttrain.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"labels = pd.read_csv(\"../input/imet-2019-fgvc6/labels.csv\")\ntrain = pd.read_csv(\"../input/imet-2019-fgvc6/train.csv\")\nsample = pd.read_csv(\"../input/imet-2019-fgvc6/sample_submission.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:58:49.444461Z","iopub.execute_input":"2022-12-06T19:58:49.444730Z","iopub.status.idle":"2022-12-06T19:58:49.634290Z","shell.execute_reply.started":"2022-12-06T19:58:49.444682Z","shell.execute_reply":"2022-12-06T19:58:49.633490Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                 id        attribute_ids\n0  1000483014d91860          147 616 813\n1  1000fe2e667721fe       51 616 734 813\n2  1001614cb89646ee                  776\n3  10041eb49b297c08  51 671 698 813 1092\n4  100501c227f8beea  13 404 492 903 1093","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>attribute_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000483014d91860</td>\n      <td>147 616 813</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000fe2e667721fe</td>\n      <td>51 616 734 813</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1001614cb89646ee</td>\n      <td>776</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10041eb49b297c08</td>\n      <td>51 671 698 813 1092</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>100501c227f8beea</td>\n      <td>13 404 492 903 1093</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!cp ../input/pytorch-pretrained-image-models/* ./\n!ls","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:58:49.635690Z","iopub.execute_input":"2022-12-06T19:58:49.635984Z","iopub.status.idle":"2022-12-06T19:58:55.429487Z","shell.execute_reply.started":"2022-12-06T19:58:49.635935Z","shell.execute_reply":"2022-12-06T19:58:55.424373Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"__notebook_source__.ipynb  densenet201.pth  resnet34.pth\ndensenet121.pth\t\t   log\t\t    resnet50.pth\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## DataLoader","metadata":{}},{"cell_type":"code","source":"# This loader is to extract 1024d features from the images.\nclass ImageDataLoader(data.DataLoader):\n    def __init__(self, root_dir: Path, \n                 df: pd.DataFrame, \n                 mode=\"train\", \n                 transforms=None):\n        self._root = root_dir\n        self.transform = transforms[mode]\n        self._img_id = (df[\"id\"] + \".png\").values\n        \n    def __len__(self):\n        return len(self._img_id)\n    \n    def __getitem__(self, idx):\n        img_id = self._img_id[idx]\n        file_name = self._root / img_id\n        img = Image.open(file_name)\n        \n        if self.transform:\n            img = self.transform(img)\n            \n        return [img]\n    \n    \ndata_transforms = {\n    'train': vision.transforms.Compose([\n        vision.transforms.RandomResizedCrop(224),\n        vision.transforms.RandomHorizontalFlip(),\n        vision.transforms.ToTensor(),\n        vision.transforms.Normalize(\n            [0.485, 0.456, 0.406], \n            [0.229, 0.224, 0.225])\n    ]),\n    'val': vision.transforms.Compose([\n        vision.transforms.Resize(256),\n        vision.transforms.CenterCrop(224),\n        vision.transforms.ToTensor(),\n        vision.transforms.Normalize(\n            [0.485, 0.456, 0.406], \n            [0.229, 0.224, 0.225])\n    ]),\n}\n\ndata_transforms[\"test\"] = data_transforms[\"val\"]","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:58:55.431274Z","iopub.execute_input":"2022-12-06T19:58:55.431674Z","iopub.status.idle":"2022-12-06T19:58:55.461017Z","shell.execute_reply.started":"2022-12-06T19:58:55.431607Z","shell.execute_reply":"2022-12-06T19:58:55.459538Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# This loader is to be used for serving image tensors for the MLP.\nclass IMetDataset(data.Dataset):\n    def __init__(self, tensor, device=\"cuda:0\", labels=None):\n        self.tensor = tensor\n        self.labels = labels\n        self.device= device\n        \n    def __len__(self):\n        return self.tensor.size(0)\n    \n    def __getitem__(self, idx):\n        tensor = self.tensor[idx, :]\n        if self.labels is not None:\n            label = self.labels[idx]\n            label_tensor = torch.zeros((1, 1103))\n            for i in label:\n                label_tensor[0, int(i)] = 1\n            label_tensor = label_tensor.to(self.device)\n            return [tensor, label_tensor]\n        else:\n            return [tensor]","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:58:55.467120Z","iopub.execute_input":"2022-12-06T19:58:55.467570Z","iopub.status.idle":"2022-12-06T19:58:55.480114Z","shell.execute_reply.started":"2022-12-06T19:58:55.467512Z","shell.execute_reply":"2022-12-06T19:58:55.479067Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"markdown","source":"Since passing images through the Densenet121 takes a lot of time, I don't want to take that time per epoch.\n\nI will calculate the output of the Densenet121 beforehand so that converting raw images to processed feature vectors happens once.","metadata":{}},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        \n    def forward(self, x):\n        return x\n\n\nclass Densenet121(nn.Module):\n    def __init__(self, pretrained: Path):\n        super(Densenet121, self).__init__()\n        self.densenet121 = vision.models.densenet121()\n        self.densenet121.load_state_dict(torch.load(pretrained))\n        self.densenet121.classifier = Classifier()\n        \n        dense = nn.Sequential(*list(self.densenet121.children())[:-1])\n        for param in dense.parameters():\n            param.requires_grad = False\n        \n    def forward(self, x):\n        return self.densenet121(x)\n    \n    \nclass MultiLayerPerceptron(nn.Module):\n    def __init__(self):\n        super(MultiLayerPerceptron, self).__init__()\n        self.linear1 = nn.Linear(1024, 1024)\n        self.relu = nn.ReLU()\n        self.linear2 = nn.Linear(1024, 1103)\n        self.dropout = nn.Dropout(0.5)\n        self.sigmoid = nn.Sigmoid()\n        \n    def forward(self, x):\n        x = self.relu(self.linear1(x))\n        x = self.dropout(x)\n        return self.sigmoid(self.linear2(x))","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:58:55.484568Z","iopub.execute_input":"2022-12-06T19:58:55.485998Z","iopub.status.idle":"2022-12-06T19:58:55.498818Z","shell.execute_reply.started":"2022-12-06T19:58:55.485916Z","shell.execute_reply":"2022-12-06T19:58:55.497857Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Data Preprocessing with Densenet121","metadata":{}},{"cell_type":"code","source":"train_dataset = ImageDataLoader(\n    root_dir=Path(\"../input/imet-2019-fgvc6/train/\"),\n    df=train,\n    mode=\"train\",\n    transforms=data_transforms)\ntrain_loader = data.DataLoader(dataset=train_dataset,\n                               shuffle=False,\n                               batch_size=128)\ntest_dataset = ImageDataLoader(\n    root_dir=Path(\"../input/imet-2019-fgvc6/test/\"),\n    df=sample,\n    mode=\"test\",\n    transforms=data_transforms)\ntest_loader = data.DataLoader(dataset=test_dataset,\n                              shuffle=False,\n                              batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:58:55.500375Z","iopub.execute_input":"2022-12-06T19:58:55.500701Z","iopub.status.idle":"2022-12-06T19:58:55.534124Z","shell.execute_reply.started":"2022-12-06T19:58:55.500632Z","shell.execute_reply":"2022-12-06T19:58:55.533352Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def get_feature_vector(df, loader, device):\n    matrix = torch.zeros((df.shape[0], 1024)).to(device)\n    model = Densenet121(\"densenet121.pth\")\n    model.to(device)\n    batch = loader.batch_size\n    for i, (i_batch,) in tqdm(enumerate(loader)):\n        i_batch = i_batch.to(device)\n        pred = model(i_batch).detach()\n        matrix[i * batch:(i + 1) * batch] = pred\n    return matrix","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:58:55.535335Z","iopub.execute_input":"2022-12-06T19:58:55.535591Z","iopub.status.idle":"2022-12-06T19:58:55.541113Z","shell.execute_reply.started":"2022-12-06T19:58:55.535550Z","shell.execute_reply":"2022-12-06T19:58:55.540198Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_tensor = get_feature_vector(train, train_loader, \"cuda:0\")\ntest_tensor = get_feature_vector(sample, test_loader, \"cuda:0\")","metadata":{"execution":{"iopub.status.busy":"2022-12-06T19:58:55.542458Z","iopub.execute_input":"2022-12-06T19:58:55.543057Z","iopub.status.idle":"2022-12-06T20:30:04.552425Z","shell.execute_reply.started":"2022-12-06T19:58:55.543007Z","shell.execute_reply":"2022-12-06T20:30:04.551661Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"854it [29:09,  1.71s/it]\n59it [01:55,  1.48s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"del train_dataset, train_loader\ndel test_dataset, test_loader\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:30:04.553671Z","iopub.execute_input":"2022-12-06T20:30:04.554116Z","iopub.status.idle":"2022-12-06T20:30:04.633274Z","shell.execute_reply.started":"2022-12-06T20:30:04.554064Z","shell.execute_reply":"2022-12-06T20:30:04.632521Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"868"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train Utilities","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, \n                 model, \n                 logger,\n                 n_splits=5,\n                 seed=42,\n                 device=\"cuda:0\",\n                 train_batch=32,\n                 valid_batch=128,\n                 kwargs={}):\n        self.model = model\n        self.logger = logger\n        self.device = device\n        self.n_splits = n_splits\n        self.seed = seed\n        self.train_batch = train_batch\n        self.valid_batch = valid_batch\n        self.kwargs = kwargs\n        \n        self.best_score = None\n        self.tag = dt.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n        self.loss_fn = nn.BCELoss(reduction=\"mean\").to(self.device)\n        \n        path = Path(f\"bin/{self.tag}\")\n        path.mkdir(exist_ok=True, parents=True)\n        self.path = path\n        \n    def fit(self, X, y, n_epochs=10):\n        train_preds = np.zeros((len(X), 1103))\n        fold = KFold(n_splits=self.n_splits, random_state=self.seed)\n        for i, (trn_idx, val_idx) in enumerate(fold.split(X)):\n            self.fold_num = i\n            self.logger.info(f\"Fold {i + 1}\")\n            X_train, X_val = X[trn_idx, :], X[val_idx, :]\n            y_train, y_val = y[trn_idx], y[val_idx]\n            \n            valid_preds = self._fit(X_train, y_train, X_val, y_val, n_epochs)\n            train_preds[val_idx] = valid_preds\n        return train_preds\n    \n    def _fit(self, X_train, y_train, X_val, y_val, n_epochs):\n        seed_torch(self.seed)\n        train_dataset = IMetDataset(X_train, labels=y_train, device=self.device)\n        train_loader = data.DataLoader(train_dataset, \n                                       batch_size=self.train_batch,\n                                       shuffle=True)\n\n        valid_dataset = IMetDataset(X_val, labels=y_val, device=self.device)\n        valid_loader = data.DataLoader(valid_dataset,\n                                       batch_size=self.valid_batch,\n                                       shuffle=False)\n        \n        model = self.model(**self.kwargs)\n        model.to(self.device)\n        \n        optimizer = optim.Adam(params=model.parameters(), \n                                lr=0.0001)\n        scheduler = CosineAnnealingLR(optimizer, T_max=n_epochs)\n        best_score = np.inf\n        mb = master_bar(range(n_epochs))\n        for epoch in mb:\n            model.train()\n            avg_loss = 0.0\n            for i_batch, y_batch in progress_bar(train_loader, parent=mb):\n                y_pred = model(i_batch)\n                loss = self.loss_fn(y_pred, y_batch)\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n                avg_loss += loss.item() / len(train_loader)\n            valid_preds, avg_val_loss = self._val(valid_loader, model)\n            scheduler.step()\n\n            self.logger.info(\"=========================================\")\n            self.logger.info(f\"Epoch {epoch + 1} / {n_epochs}\")\n            self.logger.info(\"=========================================\")\n            self.logger.info(f\"avg_loss: {avg_loss:.8f}\")\n            self.logger.info(f\"avg_val_loss: {avg_val_loss:.8f}\")\n            \n            if best_score > avg_val_loss:\n                torch.save(model.state_dict(),\n                           self.path / f\"best{self.fold_num}.pth\")\n                self.logger.info(f\"Save model at Epoch {epoch + 1}\")\n                best_score = avg_val_loss\n        model.load_state_dict(torch.load(self.path / f\"best{self.fold_num}.pth\"))\n        valid_preds, avg_val_loss = self._val(valid_loader, model)\n        self.logger.info(f\"Best Validation Loss: {avg_val_loss:.8f}\")\n        return valid_preds\n    \n    def _val(self, loader, model):\n        model.eval()\n        valid_preds = np.zeros((len(loader.dataset), 1103))\n        avg_val_loss = 0.0\n        for i, (i_batch, y_batch) in enumerate(loader):\n            with torch.no_grad():\n                y_pred = model(i_batch).detach()\n                avg_val_loss += self.loss_fn(y_pred, y_batch).item() / len(loader)\n                valid_preds[i * self.valid_batch:(i + 1) * self.valid_batch] = \\\n                    y_pred.cpu().numpy()\n        return valid_preds, avg_val_loss\n    \n    def predict(self, X):\n        dataset = IMetDataset(X, labels=None)\n        loader = data.DataLoader(dataset, \n                                 batch_size=self.valid_batch, \n                                 shuffle=False)\n        model = self.model(**self.kwargs)\n        preds = np.zeros((X.size(0), 1103))\n        for path in self.path.iterdir():\n            with timer(f\"Using {str(path)}\", self.logger):\n                model.load_state_dict(torch.load(path))\n                model.to(self.device)\n                model.eval()\n                temp = np.zeros_like(preds)\n                for i, (i_batch, ) in enumerate(loader):\n                    with torch.no_grad():\n                        y_pred = model(i_batch).detach()\n                        temp[i * self.valid_batch:(i + 1) * self.valid_batch] = \\\n                            y_pred.cpu().numpy()\n                preds += temp / self.n_splits\n        return preds","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:30:04.634554Z","iopub.execute_input":"2022-12-06T20:30:04.635021Z","iopub.status.idle":"2022-12-06T20:30:04.655163Z","shell.execute_reply.started":"2022-12-06T20:30:04.634966Z","shell.execute_reply":"2022-12-06T20:30:04.654443Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"trainer = Trainer(MultiLayerPerceptron, logger, train_batch=64, kwargs={})","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:30:04.656546Z","iopub.execute_input":"2022-12-06T20:30:04.657053Z","iopub.status.idle":"2022-12-06T20:30:04.671499Z","shell.execute_reply.started":"2022-12-06T20:30:04.656882Z","shell.execute_reply":"2022-12-06T20:30:04.670097Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"y = train.attribute_ids.map(lambda x: x.split()).values\nvalid_preds = trainer.fit(train_tensor, y, n_epochs=40)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:30:04.673605Z","iopub.execute_input":"2022-12-06T20:30:04.674248Z","iopub.status.idle":"2022-12-06T20:58:55.797220Z","shell.execute_reply.started":"2022-12-06T20:30:04.674196Z","shell.execute_reply":"2022-12-06T20:58:55.796397Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"2022-12-06 20:30:04,822 Main INFO Fold 1\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 05:47 <p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([64, 1, 1103])) that is different to the input size (torch.Size([64, 1103])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([29, 1, 1103])) that is different to the input size (torch.Size([29, 1103])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([128, 1, 1103])) that is different to the input size (torch.Size([128, 1103])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n","output_type":"stream"},{"name":"stdout","text":"2022-12-06 20:30:13,497 Main INFO =========================================\n2022-12-06 20:30:13,500 Main INFO Epoch 1 / 40\n2022-12-06 20:30:13,501 Main INFO =========================================\n2022-12-06 20:30:13,504 Main INFO avg_loss: 0.02454177\n2022-12-06 20:30:13,505 Main INFO avg_val_loss: 0.01283414\n2022-12-06 20:30:13,516 Main INFO Save model at Epoch 1\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([88, 1, 1103])) that is different to the input size (torch.Size([88, 1103])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n","output_type":"stream"},{"name":"stdout","text":"2022-12-06 20:30:22,239 Main INFO =========================================\n2022-12-06 20:30:22,240 Main INFO Epoch 2 / 40\n2022-12-06 20:30:22,244 Main INFO =========================================\n2022-12-06 20:30:22,244 Main INFO avg_loss: 0.01283906\n2022-12-06 20:30:22,247 Main INFO avg_val_loss: 0.01180768\n2022-12-06 20:30:22,265 Main INFO Save model at Epoch 2\n2022-12-06 20:30:31,211 Main INFO =========================================\n2022-12-06 20:30:31,212 Main INFO Epoch 3 / 40\n2022-12-06 20:30:31,214 Main INFO =========================================\n2022-12-06 20:30:31,215 Main INFO avg_loss: 0.01196755\n2022-12-06 20:30:31,216 Main INFO avg_val_loss: 0.01130774\n2022-12-06 20:30:31,234 Main INFO Save model at Epoch 3\n2022-12-06 20:30:39,530 Main INFO =========================================\n2022-12-06 20:30:39,531 Main INFO Epoch 4 / 40\n2022-12-06 20:30:39,532 Main INFO =========================================\n2022-12-06 20:30:39,534 Main INFO avg_loss: 0.01146331\n2022-12-06 20:30:39,535 Main INFO avg_val_loss: 0.01098127\n2022-12-06 20:30:39,552 Main INFO Save model at Epoch 4\n2022-12-06 20:30:48,511 Main INFO =========================================\n2022-12-06 20:30:48,512 Main INFO Epoch 5 / 40\n2022-12-06 20:30:48,513 Main INFO =========================================\n2022-12-06 20:30:48,514 Main INFO avg_loss: 0.01112703\n2022-12-06 20:30:48,516 Main INFO avg_val_loss: 0.01077119\n2022-12-06 20:30:48,532 Main INFO Save model at Epoch 5\n2022-12-06 20:30:57,044 Main INFO =========================================\n2022-12-06 20:30:57,045 Main INFO Epoch 6 / 40\n2022-12-06 20:30:57,047 Main INFO =========================================\n2022-12-06 20:30:57,052 Main INFO avg_loss: 0.01087024\n2022-12-06 20:30:57,053 Main INFO avg_val_loss: 0.01062706\n2022-12-06 20:30:57,074 Main INFO Save model at Epoch 6\n2022-12-06 20:31:05,976 Main INFO =========================================\n2022-12-06 20:31:05,977 Main INFO Epoch 7 / 40\n2022-12-06 20:31:05,980 Main INFO =========================================\n2022-12-06 20:31:05,982 Main INFO avg_loss: 0.01066421\n2022-12-06 20:31:05,984 Main INFO avg_val_loss: 0.01049792\n2022-12-06 20:31:06,000 Main INFO Save model at Epoch 7\n2022-12-06 20:31:14,516 Main INFO =========================================\n2022-12-06 20:31:14,517 Main INFO Epoch 8 / 40\n2022-12-06 20:31:14,520 Main INFO =========================================\n2022-12-06 20:31:14,522 Main INFO avg_loss: 0.01049352\n2022-12-06 20:31:14,523 Main INFO avg_val_loss: 0.01041777\n2022-12-06 20:31:14,539 Main INFO Save model at Epoch 8\n2022-12-06 20:31:22,869 Main INFO =========================================\n2022-12-06 20:31:22,870 Main INFO Epoch 9 / 40\n2022-12-06 20:31:22,871 Main INFO =========================================\n2022-12-06 20:31:22,873 Main INFO avg_loss: 0.01034965\n2022-12-06 20:31:22,876 Main INFO avg_val_loss: 0.01031661\n2022-12-06 20:31:22,891 Main INFO Save model at Epoch 9\n2022-12-06 20:31:31,769 Main INFO =========================================\n2022-12-06 20:31:31,770 Main INFO Epoch 10 / 40\n2022-12-06 20:31:31,771 Main INFO =========================================\n2022-12-06 20:31:31,774 Main INFO avg_loss: 0.01022593\n2022-12-06 20:31:31,775 Main INFO avg_val_loss: 0.01026870\n2022-12-06 20:31:31,791 Main INFO Save model at Epoch 10\n2022-12-06 20:31:40,692 Main INFO =========================================\n2022-12-06 20:31:40,693 Main INFO Epoch 11 / 40\n2022-12-06 20:31:40,694 Main INFO =========================================\n2022-12-06 20:31:40,696 Main INFO avg_loss: 0.01011600\n2022-12-06 20:31:40,697 Main INFO avg_val_loss: 0.01021254\n2022-12-06 20:31:40,714 Main INFO Save model at Epoch 11\n2022-12-06 20:31:49,349 Main INFO =========================================\n2022-12-06 20:31:49,350 Main INFO Epoch 12 / 40\n2022-12-06 20:31:49,350 Main INFO =========================================\n2022-12-06 20:31:49,352 Main INFO avg_loss: 0.01001316\n2022-12-06 20:31:49,354 Main INFO avg_val_loss: 0.01018549\n2022-12-06 20:31:49,370 Main INFO Save model at Epoch 12\n2022-12-06 20:31:57,877 Main INFO =========================================\n2022-12-06 20:31:57,878 Main INFO Epoch 13 / 40\n2022-12-06 20:31:57,880 Main INFO =========================================\n2022-12-06 20:31:57,881 Main INFO avg_loss: 0.00992416\n2022-12-06 20:31:57,882 Main INFO avg_val_loss: 0.01013885\n2022-12-06 20:31:57,898 Main INFO Save model at Epoch 13\n2022-12-06 20:32:06,564 Main INFO =========================================\n2022-12-06 20:32:06,565 Main INFO Epoch 14 / 40\n2022-12-06 20:32:06,568 Main INFO =========================================\n2022-12-06 20:32:06,569 Main INFO avg_loss: 0.00984490\n2022-12-06 20:32:06,570 Main INFO avg_val_loss: 0.01012242\n2022-12-06 20:32:06,585 Main INFO Save model at Epoch 14\n2022-12-06 20:32:15,115 Main INFO =========================================\n2022-12-06 20:32:15,116 Main INFO Epoch 15 / 40\n2022-12-06 20:32:15,117 Main INFO =========================================\n2022-12-06 20:32:15,119 Main INFO avg_loss: 0.00977236\n2022-12-06 20:32:15,120 Main INFO avg_val_loss: 0.01006668\n2022-12-06 20:32:15,136 Main INFO Save model at Epoch 15\n2022-12-06 20:32:23,636 Main INFO =========================================\n2022-12-06 20:32:23,637 Main INFO Epoch 16 / 40\n2022-12-06 20:32:23,639 Main INFO =========================================\n2022-12-06 20:32:23,640 Main INFO avg_loss: 0.00970250\n2022-12-06 20:32:23,641 Main INFO avg_val_loss: 0.01005639\n2022-12-06 20:32:23,656 Main INFO Save model at Epoch 16\n2022-12-06 20:32:32,156 Main INFO =========================================\n2022-12-06 20:32:32,159 Main INFO Epoch 17 / 40\n2022-12-06 20:32:32,166 Main INFO =========================================\n2022-12-06 20:32:32,168 Main INFO avg_loss: 0.00963839\n2022-12-06 20:32:32,169 Main INFO avg_val_loss: 0.01001462\n2022-12-06 20:32:32,194 Main INFO Save model at Epoch 17\n2022-12-06 20:32:41,098 Main INFO =========================================\n2022-12-06 20:32:41,101 Main INFO Epoch 18 / 40\n2022-12-06 20:32:41,103 Main INFO =========================================\n2022-12-06 20:32:41,103 Main INFO avg_loss: 0.00958042\n2022-12-06 20:32:41,105 Main INFO avg_val_loss: 0.01001030\n2022-12-06 20:32:41,126 Main INFO Save model at Epoch 18\n2022-12-06 20:32:49,819 Main INFO =========================================\n2022-12-06 20:32:49,820 Main INFO Epoch 19 / 40\n2022-12-06 20:32:49,820 Main INFO =========================================\n2022-12-06 20:32:49,822 Main INFO avg_loss: 0.00952208\n2022-12-06 20:32:49,824 Main INFO avg_val_loss: 0.01000377\n2022-12-06 20:32:49,841 Main INFO Save model at Epoch 19\n2022-12-06 20:32:58,361 Main INFO =========================================\n2022-12-06 20:32:58,362 Main INFO Epoch 20 / 40\n2022-12-06 20:32:58,363 Main INFO =========================================\n2022-12-06 20:32:58,366 Main INFO avg_loss: 0.00946847\n2022-12-06 20:32:58,367 Main INFO avg_val_loss: 0.00998579\n2022-12-06 20:32:58,383 Main INFO Save model at Epoch 20\n2022-12-06 20:33:07,361 Main INFO =========================================\n2022-12-06 20:33:07,362 Main INFO Epoch 21 / 40\n2022-12-06 20:33:07,363 Main INFO =========================================\n2022-12-06 20:33:07,365 Main INFO avg_loss: 0.00942388\n2022-12-06 20:33:07,368 Main INFO avg_val_loss: 0.00997809\n2022-12-06 20:33:07,383 Main INFO Save model at Epoch 21\n2022-12-06 20:33:15,905 Main INFO =========================================\n2022-12-06 20:33:15,906 Main INFO Epoch 22 / 40\n2022-12-06 20:33:15,908 Main INFO =========================================\n2022-12-06 20:33:15,909 Main INFO avg_loss: 0.00937750\n2022-12-06 20:33:15,911 Main INFO avg_val_loss: 0.00995989\n2022-12-06 20:33:15,927 Main INFO Save model at Epoch 22\n2022-12-06 20:33:24,205 Main INFO =========================================\n2022-12-06 20:33:24,206 Main INFO Epoch 23 / 40\n2022-12-06 20:33:24,207 Main INFO =========================================\n2022-12-06 20:33:24,208 Main INFO avg_loss: 0.00933548\n2022-12-06 20:33:24,209 Main INFO avg_val_loss: 0.00995275\n2022-12-06 20:33:24,225 Main INFO Save model at Epoch 23\n2022-12-06 20:33:32,777 Main INFO =========================================\n2022-12-06 20:33:32,778 Main INFO Epoch 24 / 40\n2022-12-06 20:33:32,780 Main INFO =========================================\n2022-12-06 20:33:32,783 Main INFO avg_loss: 0.00930134\n2022-12-06 20:33:32,784 Main INFO avg_val_loss: 0.00995193\n2022-12-06 20:33:32,800 Main INFO Save model at Epoch 24\n2022-12-06 20:33:41,857 Main INFO =========================================\n2022-12-06 20:33:41,858 Main INFO Epoch 25 / 40\n2022-12-06 20:33:41,860 Main INFO =========================================\n2022-12-06 20:33:41,861 Main INFO avg_loss: 0.00926946\n2022-12-06 20:33:41,862 Main INFO avg_val_loss: 0.00994617\n2022-12-06 20:33:41,877 Main INFO Save model at Epoch 25\n2022-12-06 20:33:50,444 Main INFO =========================================\n2022-12-06 20:33:50,445 Main INFO Epoch 26 / 40\n2022-12-06 20:33:50,447 Main INFO =========================================\n2022-12-06 20:33:50,448 Main INFO avg_loss: 0.00923448\n2022-12-06 20:33:50,449 Main INFO avg_val_loss: 0.00992744\n2022-12-06 20:33:50,465 Main INFO Save model at Epoch 26\n2022-12-06 20:33:58,995 Main INFO =========================================\n2022-12-06 20:33:58,996 Main INFO Epoch 27 / 40\n2022-12-06 20:33:58,998 Main INFO =========================================\n2022-12-06 20:33:59,000 Main INFO avg_loss: 0.00920072\n2022-12-06 20:33:59,001 Main INFO avg_val_loss: 0.00993152\n2022-12-06 20:34:07,304 Main INFO =========================================\n2022-12-06 20:34:07,305 Main INFO Epoch 28 / 40\n2022-12-06 20:34:07,306 Main INFO =========================================\n2022-12-06 20:34:07,308 Main INFO avg_loss: 0.00918267\n2022-12-06 20:34:07,311 Main INFO avg_val_loss: 0.00993041\n2022-12-06 20:34:16,492 Main INFO =========================================\n2022-12-06 20:34:16,493 Main INFO Epoch 29 / 40\n2022-12-06 20:34:16,493 Main INFO =========================================\n2022-12-06 20:34:16,495 Main INFO avg_loss: 0.00916385\n2022-12-06 20:34:16,497 Main INFO avg_val_loss: 0.00992565\n2022-12-06 20:34:16,512 Main INFO Save model at Epoch 29\n2022-12-06 20:34:25,062 Main INFO =========================================\n2022-12-06 20:34:25,063 Main INFO Epoch 30 / 40\n2022-12-06 20:34:25,064 Main INFO =========================================\n2022-12-06 20:34:25,066 Main INFO avg_loss: 0.00913749\n2022-12-06 20:34:25,069 Main INFO avg_val_loss: 0.00991141\n2022-12-06 20:34:25,085 Main INFO Save model at Epoch 30\n2022-12-06 20:34:33,619 Main INFO =========================================\n2022-12-06 20:34:33,620 Main INFO Epoch 31 / 40\n2022-12-06 20:34:33,621 Main INFO =========================================\n2022-12-06 20:34:33,622 Main INFO avg_loss: 0.00912386\n2022-12-06 20:34:33,623 Main INFO avg_val_loss: 0.00993312\n2022-12-06 20:34:42,546 Main INFO =========================================\n2022-12-06 20:34:42,548 Main INFO Epoch 32 / 40\n2022-12-06 20:34:42,549 Main INFO =========================================\n2022-12-06 20:34:42,550 Main INFO avg_loss: 0.00910216\n2022-12-06 20:34:42,551 Main INFO avg_val_loss: 0.00992080\n2022-12-06 20:34:50,932 Main INFO =========================================\n2022-12-06 20:34:50,933 Main INFO Epoch 33 / 40\n2022-12-06 20:34:50,935 Main INFO =========================================\n2022-12-06 20:34:50,936 Main INFO avg_loss: 0.00909378\n2022-12-06 20:34:50,937 Main INFO avg_val_loss: 0.00991635\n2022-12-06 20:34:59,459 Main INFO =========================================\n2022-12-06 20:34:59,460 Main INFO Epoch 34 / 40\n2022-12-06 20:34:59,461 Main INFO =========================================\n2022-12-06 20:34:59,464 Main INFO avg_loss: 0.00908207\n2022-12-06 20:34:59,465 Main INFO avg_val_loss: 0.00991164\n2022-12-06 20:35:07,970 Main INFO =========================================\n2022-12-06 20:35:07,971 Main INFO Epoch 35 / 40\n2022-12-06 20:35:07,973 Main INFO =========================================\n2022-12-06 20:35:07,974 Main INFO avg_loss: 0.00906569\n2022-12-06 20:35:07,975 Main INFO avg_val_loss: 0.00991652\n2022-12-06 20:35:16,939 Main INFO =========================================\n2022-12-06 20:35:16,940 Main INFO Epoch 36 / 40\n2022-12-06 20:35:16,942 Main INFO =========================================\n2022-12-06 20:35:16,943 Main INFO avg_loss: 0.00906423\n2022-12-06 20:35:16,944 Main INFO avg_val_loss: 0.00991390\n2022-12-06 20:35:25,359 Main INFO =========================================\n2022-12-06 20:35:25,360 Main INFO Epoch 37 / 40\n2022-12-06 20:35:25,361 Main INFO =========================================\n2022-12-06 20:35:25,363 Main INFO avg_loss: 0.00905821\n2022-12-06 20:35:25,364 Main INFO avg_val_loss: 0.00991454\n2022-12-06 20:35:33,953 Main INFO =========================================\n2022-12-06 20:35:33,954 Main INFO Epoch 38 / 40\n2022-12-06 20:35:33,956 Main INFO =========================================\n2022-12-06 20:35:33,957 Main INFO avg_loss: 0.00905152\n2022-12-06 20:35:33,958 Main INFO avg_val_loss: 0.00991165\n2022-12-06 20:35:42,545 Main INFO =========================================\n2022-12-06 20:35:42,549 Main INFO Epoch 39 / 40\n2022-12-06 20:35:42,552 Main INFO =========================================\n2022-12-06 20:35:42,555 Main INFO avg_loss: 0.00904684\n2022-12-06 20:35:42,558 Main INFO avg_val_loss: 0.00991139\n2022-12-06 20:35:42,579 Main INFO Save model at Epoch 39\n2022-12-06 20:35:51,851 Main INFO =========================================\n2022-12-06 20:35:51,852 Main INFO Epoch 40 / 40\n2022-12-06 20:35:51,853 Main INFO =========================================\n2022-12-06 20:35:51,855 Main INFO avg_loss: 0.00905031\n2022-12-06 20:35:51,856 Main INFO avg_val_loss: 0.00991227\n2022-12-06 20:35:53,325 Main INFO Best Validation Loss: 0.00991139\n2022-12-06 20:35:53,461 Main INFO Fold 2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 05:44 <p>"},"metadata":{}},{"name":"stdout","text":"2022-12-06 20:36:02,015 Main INFO =========================================\n2022-12-06 20:36:02,016 Main INFO Epoch 1 / 40\n2022-12-06 20:36:02,017 Main INFO =========================================\n2022-12-06 20:36:02,019 Main INFO avg_loss: 0.02450537\n2022-12-06 20:36:02,022 Main INFO avg_val_loss: 0.01294592\n2022-12-06 20:36:02,033 Main INFO Save model at Epoch 1\n2022-12-06 20:36:10,563 Main INFO =========================================\n2022-12-06 20:36:10,564 Main INFO Epoch 2 / 40\n2022-12-06 20:36:10,568 Main INFO =========================================\n2022-12-06 20:36:10,569 Main INFO avg_loss: 0.01280730\n2022-12-06 20:36:10,571 Main INFO avg_val_loss: 0.01189943\n2022-12-06 20:36:10,587 Main INFO Save model at Epoch 2\n2022-12-06 20:36:19,286 Main INFO =========================================\n2022-12-06 20:36:19,287 Main INFO Epoch 3 / 40\n2022-12-06 20:36:19,287 Main INFO =========================================\n2022-12-06 20:36:19,289 Main INFO avg_loss: 0.01193092\n2022-12-06 20:36:19,291 Main INFO avg_val_loss: 0.01139571\n2022-12-06 20:36:19,311 Main INFO Save model at Epoch 3\n2022-12-06 20:36:27,850 Main INFO =========================================\n2022-12-06 20:36:27,851 Main INFO Epoch 4 / 40\n2022-12-06 20:36:27,853 Main INFO =========================================\n2022-12-06 20:36:27,855 Main INFO avg_loss: 0.01143044\n2022-12-06 20:36:27,856 Main INFO avg_val_loss: 0.01108092\n2022-12-06 20:36:27,872 Main INFO Save model at Epoch 4\n2022-12-06 20:36:36,375 Main INFO =========================================\n2022-12-06 20:36:36,376 Main INFO Epoch 5 / 40\n2022-12-06 20:36:36,378 Main INFO =========================================\n2022-12-06 20:36:36,379 Main INFO avg_loss: 0.01109145\n2022-12-06 20:36:36,380 Main INFO avg_val_loss: 0.01087162\n2022-12-06 20:36:36,397 Main INFO Save model at Epoch 5\n2022-12-06 20:36:44,898 Main INFO =========================================\n2022-12-06 20:36:44,899 Main INFO Epoch 6 / 40\n2022-12-06 20:36:44,901 Main INFO =========================================\n2022-12-06 20:36:44,902 Main INFO avg_loss: 0.01083916\n2022-12-06 20:36:44,904 Main INFO avg_val_loss: 0.01074406\n2022-12-06 20:36:44,920 Main INFO Save model at Epoch 6\n2022-12-06 20:36:53,643 Main INFO =========================================\n2022-12-06 20:36:53,644 Main INFO Epoch 7 / 40\n2022-12-06 20:36:53,646 Main INFO =========================================\n2022-12-06 20:36:53,647 Main INFO avg_loss: 0.01062862\n2022-12-06 20:36:53,648 Main INFO avg_val_loss: 0.01061067\n2022-12-06 20:36:53,665 Main INFO Save model at Epoch 7\n2022-12-06 20:37:02,213 Main INFO =========================================\n2022-12-06 20:37:02,214 Main INFO Epoch 8 / 40\n2022-12-06 20:37:02,215 Main INFO =========================================\n2022-12-06 20:37:02,216 Main INFO avg_loss: 0.01045907\n2022-12-06 20:37:02,217 Main INFO avg_val_loss: 0.01052260\n2022-12-06 20:37:02,234 Main INFO Save model at Epoch 8\n2022-12-06 20:37:10,822 Main INFO =========================================\n2022-12-06 20:37:10,823 Main INFO Epoch 9 / 40\n2022-12-06 20:37:10,824 Main INFO =========================================\n2022-12-06 20:37:10,825 Main INFO avg_loss: 0.01031716\n2022-12-06 20:37:10,826 Main INFO avg_val_loss: 0.01042967\n2022-12-06 20:37:10,844 Main INFO Save model at Epoch 9\n2022-12-06 20:37:19,711 Main INFO =========================================\n2022-12-06 20:37:19,712 Main INFO Epoch 10 / 40\n2022-12-06 20:37:19,713 Main INFO =========================================\n2022-12-06 20:37:19,715 Main INFO avg_loss: 0.01019304\n2022-12-06 20:37:19,718 Main INFO avg_val_loss: 0.01038997\n2022-12-06 20:37:19,734 Main INFO Save model at Epoch 10\n2022-12-06 20:37:28,236 Main INFO =========================================\n2022-12-06 20:37:28,236 Main INFO Epoch 11 / 40\n2022-12-06 20:37:28,239 Main INFO =========================================\n2022-12-06 20:37:28,240 Main INFO avg_loss: 0.01008413\n2022-12-06 20:37:28,241 Main INFO avg_val_loss: 0.01033877\n2022-12-06 20:37:28,257 Main INFO Save model at Epoch 11\n2022-12-06 20:37:36,539 Main INFO =========================================\n2022-12-06 20:37:36,540 Main INFO Epoch 12 / 40\n2022-12-06 20:37:36,542 Main INFO =========================================\n2022-12-06 20:37:36,543 Main INFO avg_loss: 0.00998617\n2022-12-06 20:37:36,544 Main INFO avg_val_loss: 0.01030023\n2022-12-06 20:37:36,561 Main INFO Save model at Epoch 12\n2022-12-06 20:37:45,066 Main INFO =========================================\n2022-12-06 20:37:45,067 Main INFO Epoch 13 / 40\n2022-12-06 20:37:45,069 Main INFO =========================================\n2022-12-06 20:37:45,070 Main INFO avg_loss: 0.00989648\n2022-12-06 20:37:45,071 Main INFO avg_val_loss: 0.01023838\n2022-12-06 20:37:45,087 Main INFO Save model at Epoch 13\n2022-12-06 20:37:54,268 Main INFO =========================================\n2022-12-06 20:37:54,269 Main INFO Epoch 14 / 40\n2022-12-06 20:37:54,271 Main INFO =========================================\n2022-12-06 20:37:54,273 Main INFO avg_loss: 0.00981418\n2022-12-06 20:37:54,276 Main INFO avg_val_loss: 0.01024183\n2022-12-06 20:38:02,792 Main INFO =========================================\n2022-12-06 20:38:02,793 Main INFO Epoch 15 / 40\n2022-12-06 20:38:02,795 Main INFO =========================================\n2022-12-06 20:38:02,796 Main INFO avg_loss: 0.00974235\n2022-12-06 20:38:02,797 Main INFO avg_val_loss: 0.01019629\n2022-12-06 20:38:02,811 Main INFO Save model at Epoch 15\n2022-12-06 20:38:11,309 Main INFO =========================================\n2022-12-06 20:38:11,310 Main INFO Epoch 16 / 40\n2022-12-06 20:38:11,311 Main INFO =========================================\n2022-12-06 20:38:11,313 Main INFO avg_loss: 0.00967290\n2022-12-06 20:38:11,315 Main INFO avg_val_loss: 0.01017301\n2022-12-06 20:38:11,331 Main INFO Save model at Epoch 16\n2022-12-06 20:38:19,613 Main INFO =========================================\n2022-12-06 20:38:19,614 Main INFO Epoch 17 / 40\n2022-12-06 20:38:19,616 Main INFO =========================================\n2022-12-06 20:38:19,617 Main INFO avg_loss: 0.00960679\n2022-12-06 20:38:19,618 Main INFO avg_val_loss: 0.01013757\n2022-12-06 20:38:19,633 Main INFO Save model at Epoch 17\n2022-12-06 20:38:28,692 Main INFO =========================================\n2022-12-06 20:38:28,693 Main INFO Epoch 18 / 40\n2022-12-06 20:38:28,694 Main INFO =========================================\n2022-12-06 20:38:28,696 Main INFO avg_loss: 0.00954737\n2022-12-06 20:38:28,699 Main INFO avg_val_loss: 0.01013729\n2022-12-06 20:38:28,712 Main INFO Save model at Epoch 18\n2022-12-06 20:38:37,280 Main INFO =========================================\n2022-12-06 20:38:37,281 Main INFO Epoch 19 / 40\n2022-12-06 20:38:37,283 Main INFO =========================================\n2022-12-06 20:38:37,284 Main INFO avg_loss: 0.00949346\n2022-12-06 20:38:37,285 Main INFO avg_val_loss: 0.01012510\n2022-12-06 20:38:37,302 Main INFO Save model at Epoch 19\n2022-12-06 20:38:45,852 Main INFO =========================================\n2022-12-06 20:38:45,853 Main INFO Epoch 20 / 40\n2022-12-06 20:38:45,854 Main INFO =========================================\n2022-12-06 20:38:45,856 Main INFO avg_loss: 0.00944079\n2022-12-06 20:38:45,857 Main INFO avg_val_loss: 0.01010659\n2022-12-06 20:38:45,870 Main INFO Save model at Epoch 20\n2022-12-06 20:38:54,571 Main INFO =========================================\n2022-12-06 20:38:54,572 Main INFO Epoch 21 / 40\n2022-12-06 20:38:54,573 Main INFO =========================================\n2022-12-06 20:38:54,574 Main INFO avg_loss: 0.00939185\n2022-12-06 20:38:54,575 Main INFO avg_val_loss: 0.01010453\n2022-12-06 20:38:54,592 Main INFO Save model at Epoch 21\n2022-12-06 20:39:03,110 Main INFO =========================================\n2022-12-06 20:39:03,111 Main INFO Epoch 22 / 40\n2022-12-06 20:39:03,112 Main INFO =========================================\n2022-12-06 20:39:03,115 Main INFO avg_loss: 0.00934578\n2022-12-06 20:39:03,117 Main INFO avg_val_loss: 0.01007739\n2022-12-06 20:39:03,133 Main INFO Save model at Epoch 22\n2022-12-06 20:39:11,677 Main INFO =========================================\n2022-12-06 20:39:11,678 Main INFO Epoch 23 / 40\n2022-12-06 20:39:11,680 Main INFO =========================================\n2022-12-06 20:39:11,681 Main INFO avg_loss: 0.00930875\n2022-12-06 20:39:11,682 Main INFO avg_val_loss: 0.01008022\n2022-12-06 20:39:20,156 Main INFO =========================================\n2022-12-06 20:39:20,157 Main INFO Epoch 24 / 40\n2022-12-06 20:39:20,160 Main INFO =========================================\n2022-12-06 20:39:20,161 Main INFO avg_loss: 0.00927389\n2022-12-06 20:39:20,162 Main INFO avg_val_loss: 0.01007561\n2022-12-06 20:39:20,177 Main INFO Save model at Epoch 24\n2022-12-06 20:39:29,046 Main INFO =========================================\n2022-12-06 20:39:29,047 Main INFO Epoch 25 / 40\n2022-12-06 20:39:29,049 Main INFO =========================================\n2022-12-06 20:39:29,050 Main INFO avg_loss: 0.00923863\n2022-12-06 20:39:29,051 Main INFO avg_val_loss: 0.01007071\n2022-12-06 20:39:29,067 Main INFO Save model at Epoch 25\n2022-12-06 20:39:37,362 Main INFO =========================================\n2022-12-06 20:39:37,363 Main INFO Epoch 26 / 40\n2022-12-06 20:39:37,364 Main INFO =========================================\n2022-12-06 20:39:37,366 Main INFO avg_loss: 0.00920286\n2022-12-06 20:39:37,367 Main INFO avg_val_loss: 0.01005481\n2022-12-06 20:39:37,381 Main INFO Save model at Epoch 26\n2022-12-06 20:39:45,952 Main INFO =========================================\n2022-12-06 20:39:45,953 Main INFO Epoch 27 / 40\n2022-12-06 20:39:45,954 Main INFO =========================================\n2022-12-06 20:39:45,957 Main INFO avg_loss: 0.00917612\n2022-12-06 20:39:45,958 Main INFO avg_val_loss: 0.01006375\n2022-12-06 20:39:54,522 Main INFO =========================================\n2022-12-06 20:39:54,523 Main INFO Epoch 28 / 40\n2022-12-06 20:39:54,524 Main INFO =========================================\n2022-12-06 20:39:54,527 Main INFO avg_loss: 0.00915037\n2022-12-06 20:39:54,528 Main INFO avg_val_loss: 0.01005543\n2022-12-06 20:40:03,665 Main INFO =========================================\n2022-12-06 20:40:03,666 Main INFO Epoch 29 / 40\n2022-12-06 20:40:03,668 Main INFO =========================================\n2022-12-06 20:40:03,669 Main INFO avg_loss: 0.00912992\n2022-12-06 20:40:03,670 Main INFO avg_val_loss: 0.01004871\n2022-12-06 20:40:03,686 Main INFO Save model at Epoch 29\n2022-12-06 20:40:12,182 Main INFO =========================================\n2022-12-06 20:40:12,186 Main INFO Epoch 30 / 40\n2022-12-06 20:40:12,189 Main INFO =========================================\n2022-12-06 20:40:12,191 Main INFO avg_loss: 0.00910990\n2022-12-06 20:40:12,194 Main INFO avg_val_loss: 0.01003652\n2022-12-06 20:40:12,214 Main INFO Save model at Epoch 30\n2022-12-06 20:40:20,516 Main INFO =========================================\n2022-12-06 20:40:20,517 Main INFO Epoch 31 / 40\n2022-12-06 20:40:20,518 Main INFO =========================================\n2022-12-06 20:40:20,520 Main INFO avg_loss: 0.00908542\n2022-12-06 20:40:20,523 Main INFO avg_val_loss: 0.01006027\n2022-12-06 20:40:29,408 Main INFO =========================================\n2022-12-06 20:40:29,409 Main INFO Epoch 32 / 40\n2022-12-06 20:40:29,411 Main INFO =========================================\n2022-12-06 20:40:29,412 Main INFO avg_loss: 0.00907089\n2022-12-06 20:40:29,413 Main INFO avg_val_loss: 0.01003518\n2022-12-06 20:40:29,427 Main INFO Save model at Epoch 32\n2022-12-06 20:40:38,119 Main INFO =========================================\n2022-12-06 20:40:38,120 Main INFO Epoch 33 / 40\n2022-12-06 20:40:38,121 Main INFO =========================================\n2022-12-06 20:40:38,123 Main INFO avg_loss: 0.00906128\n2022-12-06 20:40:38,126 Main INFO avg_val_loss: 0.01003620\n2022-12-06 20:40:46,665 Main INFO =========================================\n2022-12-06 20:40:46,666 Main INFO Epoch 34 / 40\n2022-12-06 20:40:46,668 Main INFO =========================================\n2022-12-06 20:40:46,669 Main INFO avg_loss: 0.00904935\n2022-12-06 20:40:46,670 Main INFO avg_val_loss: 0.01003560\n2022-12-06 20:40:54,950 Main INFO =========================================\n2022-12-06 20:40:54,951 Main INFO Epoch 35 / 40\n2022-12-06 20:40:54,952 Main INFO =========================================\n2022-12-06 20:40:54,954 Main INFO avg_loss: 0.00903783\n2022-12-06 20:40:54,956 Main INFO avg_val_loss: 0.01003964\n2022-12-06 20:41:03,948 Main INFO =========================================\n2022-12-06 20:41:03,949 Main INFO Epoch 36 / 40\n2022-12-06 20:41:03,950 Main INFO =========================================\n2022-12-06 20:41:03,952 Main INFO avg_loss: 0.00903702\n2022-12-06 20:41:03,955 Main INFO avg_val_loss: 0.01003564\n2022-12-06 20:41:12,532 Main INFO =========================================\n2022-12-06 20:41:12,533 Main INFO Epoch 37 / 40\n2022-12-06 20:41:12,534 Main INFO =========================================\n2022-12-06 20:41:12,537 Main INFO avg_loss: 0.00902502\n2022-12-06 20:41:12,538 Main INFO avg_val_loss: 0.01003739\n2022-12-06 20:41:21,042 Main INFO =========================================\n2022-12-06 20:41:21,043 Main INFO Epoch 38 / 40\n2022-12-06 20:41:21,044 Main INFO =========================================\n2022-12-06 20:41:21,046 Main INFO avg_loss: 0.00902062\n2022-12-06 20:41:21,049 Main INFO avg_val_loss: 0.01003517\n2022-12-06 20:41:21,061 Main INFO Save model at Epoch 38\n2022-12-06 20:41:29,529 Main INFO =========================================\n2022-12-06 20:41:29,530 Main INFO Epoch 39 / 40\n2022-12-06 20:41:29,532 Main INFO =========================================\n2022-12-06 20:41:29,533 Main INFO avg_loss: 0.00902116\n2022-12-06 20:41:29,534 Main INFO avg_val_loss: 0.01003528\n2022-12-06 20:41:38,236 Main INFO =========================================\n2022-12-06 20:41:38,237 Main INFO Epoch 40 / 40\n2022-12-06 20:41:38,240 Main INFO =========================================\n2022-12-06 20:41:38,241 Main INFO avg_loss: 0.00902330\n2022-12-06 20:41:38,242 Main INFO avg_val_loss: 0.01003738\n2022-12-06 20:41:39,808 Main INFO Best Validation Loss: 0.01003517\n2022-12-06 20:41:39,982 Main INFO Fold 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 05:44 <p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([30, 1, 1103])) that is different to the input size (torch.Size([30, 1103])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n","output_type":"stream"},{"name":"stdout","text":"2022-12-06 20:41:48,433 Main INFO =========================================\n2022-12-06 20:41:48,434 Main INFO Epoch 1 / 40\n2022-12-06 20:41:48,436 Main INFO =========================================\n2022-12-06 20:41:48,437 Main INFO avg_loss: 0.02453290\n2022-12-06 20:41:48,438 Main INFO avg_val_loss: 0.01290982\n2022-12-06 20:41:48,449 Main INFO Save model at Epoch 1\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([87, 1, 1103])) that is different to the input size (torch.Size([87, 1103])) is deprecated. Please ensure they have the same size.\n  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n","output_type":"stream"},{"name":"stdout","text":"2022-12-06 20:41:56,952 Main INFO =========================================\n2022-12-06 20:41:56,952 Main INFO Epoch 2 / 40\n2022-12-06 20:41:56,953 Main INFO =========================================\n2022-12-06 20:41:56,955 Main INFO avg_loss: 0.01281260\n2022-12-06 20:41:56,958 Main INFO avg_val_loss: 0.01185245\n2022-12-06 20:41:56,974 Main INFO Save model at Epoch 2\n2022-12-06 20:42:05,928 Main INFO =========================================\n2022-12-06 20:42:05,929 Main INFO Epoch 3 / 40\n2022-12-06 20:42:05,930 Main INFO =========================================\n2022-12-06 20:42:05,934 Main INFO avg_loss: 0.01194475\n2022-12-06 20:42:05,935 Main INFO avg_val_loss: 0.01135724\n2022-12-06 20:42:05,951 Main INFO Save model at Epoch 3\n2022-12-06 20:42:14,488 Main INFO =========================================\n2022-12-06 20:42:14,489 Main INFO Epoch 4 / 40\n2022-12-06 20:42:14,490 Main INFO =========================================\n2022-12-06 20:42:14,491 Main INFO avg_loss: 0.01144783\n2022-12-06 20:42:14,492 Main INFO avg_val_loss: 0.01106114\n2022-12-06 20:42:14,509 Main INFO Save model at Epoch 4\n2022-12-06 20:42:22,778 Main INFO =========================================\n2022-12-06 20:42:22,779 Main INFO Epoch 5 / 40\n2022-12-06 20:42:22,780 Main INFO =========================================\n2022-12-06 20:42:22,781 Main INFO avg_loss: 0.01110548\n2022-12-06 20:42:22,783 Main INFO avg_val_loss: 0.01084661\n2022-12-06 20:42:22,796 Main INFO Save model at Epoch 5\n2022-12-06 20:42:31,325 Main INFO =========================================\n2022-12-06 20:42:31,326 Main INFO Epoch 6 / 40\n2022-12-06 20:42:31,327 Main INFO =========================================\n2022-12-06 20:42:31,329 Main INFO avg_loss: 0.01084993\n2022-12-06 20:42:31,330 Main INFO avg_val_loss: 0.01068184\n2022-12-06 20:42:31,347 Main INFO Save model at Epoch 6\n2022-12-06 20:42:40,454 Main INFO =========================================\n2022-12-06 20:42:40,455 Main INFO Epoch 7 / 40\n2022-12-06 20:42:40,456 Main INFO =========================================\n2022-12-06 20:42:40,459 Main INFO avg_loss: 0.01064215\n2022-12-06 20:42:40,460 Main INFO avg_val_loss: 0.01055851\n2022-12-06 20:42:40,473 Main INFO Save model at Epoch 7\n2022-12-06 20:42:48,959 Main INFO =========================================\n2022-12-06 20:42:48,960 Main INFO Epoch 8 / 40\n2022-12-06 20:42:48,962 Main INFO =========================================\n2022-12-06 20:42:48,964 Main INFO avg_loss: 0.01047158\n2022-12-06 20:42:48,965 Main INFO avg_val_loss: 0.01047176\n2022-12-06 20:42:48,981 Main INFO Save model at Epoch 8\n2022-12-06 20:42:57,480 Main INFO =========================================\n2022-12-06 20:42:57,481 Main INFO Epoch 9 / 40\n2022-12-06 20:42:57,483 Main INFO =========================================\n2022-12-06 20:42:57,484 Main INFO avg_loss: 0.01033374\n2022-12-06 20:42:57,485 Main INFO avg_val_loss: 0.01040122\n2022-12-06 20:42:57,499 Main INFO Save model at Epoch 9\n2022-12-06 20:43:05,832 Main INFO =========================================\n2022-12-06 20:43:05,833 Main INFO Epoch 10 / 40\n2022-12-06 20:43:05,834 Main INFO =========================================\n2022-12-06 20:43:05,835 Main INFO avg_loss: 0.01020469\n2022-12-06 20:43:05,836 Main INFO avg_val_loss: 0.01032785\n2022-12-06 20:43:05,852 Main INFO Save model at Epoch 10\n2022-12-06 20:43:14,756 Main INFO =========================================\n2022-12-06 20:43:14,757 Main INFO Epoch 11 / 40\n2022-12-06 20:43:14,759 Main INFO =========================================\n2022-12-06 20:43:14,760 Main INFO avg_loss: 0.01009528\n2022-12-06 20:43:14,762 Main INFO avg_val_loss: 0.01029861\n2022-12-06 20:43:14,778 Main INFO Save model at Epoch 11\n2022-12-06 20:43:23,285 Main INFO =========================================\n2022-12-06 20:43:23,286 Main INFO Epoch 12 / 40\n2022-12-06 20:43:23,287 Main INFO =========================================\n2022-12-06 20:43:23,290 Main INFO avg_loss: 0.01000126\n2022-12-06 20:43:23,292 Main INFO avg_val_loss: 0.01024277\n2022-12-06 20:43:23,305 Main INFO Save model at Epoch 12\n2022-12-06 20:43:31,785 Main INFO =========================================\n2022-12-06 20:43:31,786 Main INFO Epoch 13 / 40\n2022-12-06 20:43:31,788 Main INFO =========================================\n2022-12-06 20:43:31,789 Main INFO avg_loss: 0.00990840\n2022-12-06 20:43:31,790 Main INFO avg_val_loss: 0.01020952\n2022-12-06 20:43:31,806 Main INFO Save model at Epoch 13\n2022-12-06 20:43:40,523 Main INFO =========================================\n2022-12-06 20:43:40,524 Main INFO Epoch 14 / 40\n2022-12-06 20:43:40,526 Main INFO =========================================\n2022-12-06 20:43:40,527 Main INFO avg_loss: 0.00982887\n2022-12-06 20:43:40,528 Main INFO avg_val_loss: 0.01019040\n2022-12-06 20:43:40,544 Main INFO Save model at Epoch 14\n2022-12-06 20:43:49,439 Main INFO =========================================\n2022-12-06 20:43:49,440 Main INFO Epoch 15 / 40\n2022-12-06 20:43:49,441 Main INFO =========================================\n2022-12-06 20:43:49,445 Main INFO avg_loss: 0.00974844\n2022-12-06 20:43:49,446 Main INFO avg_val_loss: 0.01016401\n2022-12-06 20:43:49,460 Main INFO Save model at Epoch 15\n2022-12-06 20:43:58,077 Main INFO =========================================\n2022-12-06 20:43:58,078 Main INFO Epoch 16 / 40\n2022-12-06 20:43:58,079 Main INFO =========================================\n2022-12-06 20:43:58,079 Main INFO avg_loss: 0.00967291\n2022-12-06 20:43:58,082 Main INFO avg_val_loss: 0.01012534\n2022-12-06 20:43:58,099 Main INFO Save model at Epoch 16\n2022-12-06 20:44:06,646 Main INFO =========================================\n2022-12-06 20:44:06,647 Main INFO Epoch 17 / 40\n2022-12-06 20:44:06,650 Main INFO =========================================\n2022-12-06 20:44:06,652 Main INFO avg_loss: 0.00961538\n2022-12-06 20:44:06,654 Main INFO avg_val_loss: 0.01011243\n2022-12-06 20:44:06,669 Main INFO Save model at Epoch 17\n2022-12-06 20:44:15,569 Main INFO =========================================\n2022-12-06 20:44:15,570 Main INFO Epoch 18 / 40\n2022-12-06 20:44:15,572 Main INFO =========================================\n2022-12-06 20:44:15,573 Main INFO avg_loss: 0.00955297\n2022-12-06 20:44:15,574 Main INFO avg_val_loss: 0.01010307\n2022-12-06 20:44:15,590 Main INFO Save model at Epoch 18\n2022-12-06 20:44:23,861 Main INFO =========================================\n2022-12-06 20:44:23,862 Main INFO Epoch 19 / 40\n2022-12-06 20:44:23,865 Main INFO =========================================\n2022-12-06 20:44:23,866 Main INFO avg_loss: 0.00950151\n2022-12-06 20:44:23,867 Main INFO avg_val_loss: 0.01007388\n2022-12-06 20:44:23,883 Main INFO Save model at Epoch 19\n2022-12-06 20:44:32,377 Main INFO =========================================\n2022-12-06 20:44:32,378 Main INFO Epoch 20 / 40\n2022-12-06 20:44:32,379 Main INFO =========================================\n2022-12-06 20:44:32,380 Main INFO avg_loss: 0.00945220\n2022-12-06 20:44:32,382 Main INFO avg_val_loss: 0.01005826\n2022-12-06 20:44:32,398 Main INFO Save model at Epoch 20\n2022-12-06 20:44:40,966 Main INFO =========================================\n2022-12-06 20:44:40,967 Main INFO Epoch 21 / 40\n2022-12-06 20:44:40,968 Main INFO =========================================\n2022-12-06 20:44:40,969 Main INFO avg_loss: 0.00940215\n2022-12-06 20:44:40,971 Main INFO avg_val_loss: 0.01004908\n2022-12-06 20:44:40,988 Main INFO Save model at Epoch 21\n2022-12-06 20:44:49,903 Main INFO =========================================\n2022-12-06 20:44:49,904 Main INFO Epoch 22 / 40\n2022-12-06 20:44:49,905 Main INFO =========================================\n2022-12-06 20:44:49,907 Main INFO avg_loss: 0.00935885\n2022-12-06 20:44:49,910 Main INFO avg_val_loss: 0.01005492\n2022-12-06 20:44:58,424 Main INFO =========================================\n2022-12-06 20:44:58,425 Main INFO Epoch 23 / 40\n2022-12-06 20:44:58,427 Main INFO =========================================\n2022-12-06 20:44:58,428 Main INFO avg_loss: 0.00931846\n2022-12-06 20:44:58,431 Main INFO avg_val_loss: 0.01003461\n2022-12-06 20:44:58,446 Main INFO Save model at Epoch 23\n2022-12-06 20:45:06,760 Main INFO =========================================\n2022-12-06 20:45:06,761 Main INFO Epoch 24 / 40\n2022-12-06 20:45:06,764 Main INFO =========================================\n2022-12-06 20:45:06,765 Main INFO avg_loss: 0.00927636\n2022-12-06 20:45:06,766 Main INFO avg_val_loss: 0.01002606\n2022-12-06 20:45:06,782 Main INFO Save model at Epoch 24\n2022-12-06 20:45:15,847 Main INFO =========================================\n2022-12-06 20:45:15,848 Main INFO Epoch 25 / 40\n2022-12-06 20:45:15,850 Main INFO =========================================\n2022-12-06 20:45:15,851 Main INFO avg_loss: 0.00924515\n2022-12-06 20:45:15,852 Main INFO avg_val_loss: 0.01003155\n2022-12-06 20:45:24,347 Main INFO =========================================\n2022-12-06 20:45:24,348 Main INFO Epoch 26 / 40\n2022-12-06 20:45:24,351 Main INFO =========================================\n2022-12-06 20:45:24,352 Main INFO avg_loss: 0.00921152\n2022-12-06 20:45:24,352 Main INFO avg_val_loss: 0.01001433\n2022-12-06 20:45:24,369 Main INFO Save model at Epoch 26\n2022-12-06 20:45:32,847 Main INFO =========================================\n2022-12-06 20:45:32,849 Main INFO Epoch 27 / 40\n2022-12-06 20:45:32,850 Main INFO =========================================\n2022-12-06 20:45:32,851 Main INFO avg_loss: 0.00918587\n2022-12-06 20:45:32,852 Main INFO avg_val_loss: 0.01001439\n2022-12-06 20:45:41,224 Main INFO =========================================\n2022-12-06 20:45:41,225 Main INFO Epoch 28 / 40\n2022-12-06 20:45:41,225 Main INFO =========================================\n2022-12-06 20:45:41,229 Main INFO avg_loss: 0.00915863\n2022-12-06 20:45:41,230 Main INFO avg_val_loss: 0.01002128\n2022-12-06 20:45:50,207 Main INFO =========================================\n2022-12-06 20:45:50,208 Main INFO Epoch 29 / 40\n2022-12-06 20:45:50,210 Main INFO =========================================\n2022-12-06 20:45:50,211 Main INFO avg_loss: 0.00913962\n2022-12-06 20:45:50,212 Main INFO avg_val_loss: 0.01001538\n2022-12-06 20:45:58,744 Main INFO =========================================\n2022-12-06 20:45:58,745 Main INFO Epoch 30 / 40\n2022-12-06 20:45:58,746 Main INFO =========================================\n2022-12-06 20:45:58,748 Main INFO avg_loss: 0.00911436\n2022-12-06 20:45:58,749 Main INFO avg_val_loss: 0.01001057\n2022-12-06 20:45:58,766 Main INFO Save model at Epoch 30\n2022-12-06 20:46:07,219 Main INFO =========================================\n2022-12-06 20:46:07,220 Main INFO Epoch 31 / 40\n2022-12-06 20:46:07,221 Main INFO =========================================\n2022-12-06 20:46:07,223 Main INFO avg_loss: 0.00909683\n2022-12-06 20:46:07,224 Main INFO avg_val_loss: 0.01000863\n2022-12-06 20:46:07,243 Main INFO Save model at Epoch 31\n2022-12-06 20:46:15,775 Main INFO =========================================\n2022-12-06 20:46:15,776 Main INFO Epoch 32 / 40\n2022-12-06 20:46:15,777 Main INFO =========================================\n2022-12-06 20:46:15,779 Main INFO avg_loss: 0.00907935\n2022-12-06 20:46:15,782 Main INFO avg_val_loss: 0.01001073\n2022-12-06 20:46:24,448 Main INFO =========================================\n2022-12-06 20:46:24,449 Main INFO Epoch 33 / 40\n2022-12-06 20:46:24,450 Main INFO =========================================\n2022-12-06 20:46:24,454 Main INFO avg_loss: 0.00907096\n2022-12-06 20:46:24,455 Main INFO avg_val_loss: 0.01001013\n2022-12-06 20:46:32,992 Main INFO =========================================\n2022-12-06 20:46:32,993 Main INFO Epoch 34 / 40\n2022-12-06 20:46:32,995 Main INFO =========================================\n2022-12-06 20:46:32,996 Main INFO avg_loss: 0.00905815\n2022-12-06 20:46:32,997 Main INFO avg_val_loss: 0.01000432\n2022-12-06 20:46:33,013 Main INFO Save model at Epoch 34\n2022-12-06 20:46:41,598 Main INFO =========================================\n2022-12-06 20:46:41,599 Main INFO Epoch 35 / 40\n2022-12-06 20:46:41,599 Main INFO =========================================\n2022-12-06 20:46:41,601 Main INFO avg_loss: 0.00905394\n2022-12-06 20:46:41,602 Main INFO avg_val_loss: 0.01000006\n2022-12-06 20:46:41,619 Main INFO Save model at Epoch 35\n2022-12-06 20:46:50,602 Main INFO =========================================\n2022-12-06 20:46:50,603 Main INFO Epoch 36 / 40\n2022-12-06 20:46:50,604 Main INFO =========================================\n2022-12-06 20:46:50,606 Main INFO avg_loss: 0.00903645\n2022-12-06 20:46:50,607 Main INFO avg_val_loss: 0.00999832\n2022-12-06 20:46:50,623 Main INFO Save model at Epoch 36\n2022-12-06 20:46:59,089 Main INFO =========================================\n2022-12-06 20:46:59,090 Main INFO Epoch 37 / 40\n2022-12-06 20:46:59,094 Main INFO =========================================\n2022-12-06 20:46:59,095 Main INFO avg_loss: 0.00903049\n2022-12-06 20:46:59,097 Main INFO avg_val_loss: 0.01000061\n2022-12-06 20:47:07,414 Main INFO =========================================\n2022-12-06 20:47:07,415 Main INFO Epoch 38 / 40\n2022-12-06 20:47:07,418 Main INFO =========================================\n2022-12-06 20:47:07,419 Main INFO avg_loss: 0.00903083\n2022-12-06 20:47:07,419 Main INFO avg_val_loss: 0.00999923\n2022-12-06 20:47:15,961 Main INFO =========================================\n2022-12-06 20:47:15,962 Main INFO Epoch 39 / 40\n2022-12-06 20:47:15,963 Main INFO =========================================\n2022-12-06 20:47:15,964 Main INFO avg_loss: 0.00902244\n2022-12-06 20:47:15,965 Main INFO avg_val_loss: 0.00999869\n2022-12-06 20:47:24,922 Main INFO =========================================\n2022-12-06 20:47:24,923 Main INFO Epoch 40 / 40\n2022-12-06 20:47:24,925 Main INFO =========================================\n2022-12-06 20:47:24,926 Main INFO avg_loss: 0.00902691\n2022-12-06 20:47:24,929 Main INFO avg_val_loss: 0.00999830\n2022-12-06 20:47:24,944 Main INFO Save model at Epoch 40\n2022-12-06 20:47:26,417 Main INFO Best Validation Loss: 0.00999830\n2022-12-06 20:47:26,566 Main INFO Fold 4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 05:41 <p>"},"metadata":{}},{"name":"stdout","text":"2022-12-06 20:47:35,085 Main INFO =========================================\n2022-12-06 20:47:35,086 Main INFO Epoch 1 / 40\n2022-12-06 20:47:35,089 Main INFO =========================================\n2022-12-06 20:47:35,090 Main INFO avg_loss: 0.02452138\n2022-12-06 20:47:35,091 Main INFO avg_val_loss: 0.01297089\n2022-12-06 20:47:35,103 Main INFO Save model at Epoch 1\n2022-12-06 20:47:43,650 Main INFO =========================================\n2022-12-06 20:47:43,651 Main INFO Epoch 2 / 40\n2022-12-06 20:47:43,651 Main INFO =========================================\n2022-12-06 20:47:43,653 Main INFO avg_loss: 0.01280638\n2022-12-06 20:47:43,654 Main INFO avg_val_loss: 0.01190094\n2022-12-06 20:47:43,669 Main INFO Save model at Epoch 2\n2022-12-06 20:47:52,040 Main INFO =========================================\n2022-12-06 20:47:52,041 Main INFO Epoch 3 / 40\n2022-12-06 20:47:52,044 Main INFO =========================================\n2022-12-06 20:47:52,045 Main INFO avg_loss: 0.01193970\n2022-12-06 20:47:52,046 Main INFO avg_val_loss: 0.01139716\n2022-12-06 20:47:52,064 Main INFO Save model at Epoch 3\n2022-12-06 20:48:01,234 Main INFO =========================================\n2022-12-06 20:48:01,235 Main INFO Epoch 4 / 40\n2022-12-06 20:48:01,236 Main INFO =========================================\n2022-12-06 20:48:01,238 Main INFO avg_loss: 0.01143486\n2022-12-06 20:48:01,239 Main INFO avg_val_loss: 0.01108325\n2022-12-06 20:48:01,255 Main INFO Save model at Epoch 4\n2022-12-06 20:48:09,831 Main INFO =========================================\n2022-12-06 20:48:09,832 Main INFO Epoch 5 / 40\n2022-12-06 20:48:09,834 Main INFO =========================================\n2022-12-06 20:48:09,835 Main INFO avg_loss: 0.01109406\n2022-12-06 20:48:09,837 Main INFO avg_val_loss: 0.01086487\n2022-12-06 20:48:09,854 Main INFO Save model at Epoch 5\n2022-12-06 20:48:18,408 Main INFO =========================================\n2022-12-06 20:48:18,409 Main INFO Epoch 6 / 40\n2022-12-06 20:48:18,409 Main INFO =========================================\n2022-12-06 20:48:18,412 Main INFO avg_loss: 0.01083978\n2022-12-06 20:48:18,413 Main INFO avg_val_loss: 0.01072420\n2022-12-06 20:48:18,429 Main INFO Save model at Epoch 6\n2022-12-06 20:48:26,798 Main INFO =========================================\n2022-12-06 20:48:26,801 Main INFO Epoch 7 / 40\n2022-12-06 20:48:26,802 Main INFO =========================================\n2022-12-06 20:48:26,803 Main INFO avg_loss: 0.01063783\n2022-12-06 20:48:26,806 Main INFO avg_val_loss: 0.01059297\n2022-12-06 20:48:26,826 Main INFO Save model at Epoch 7\n2022-12-06 20:48:35,244 Main INFO =========================================\n2022-12-06 20:48:35,245 Main INFO Epoch 8 / 40\n2022-12-06 20:48:35,247 Main INFO =========================================\n2022-12-06 20:48:35,248 Main INFO avg_loss: 0.01046772\n2022-12-06 20:48:35,249 Main INFO avg_val_loss: 0.01049422\n2022-12-06 20:48:35,263 Main INFO Save model at Epoch 8\n2022-12-06 20:48:43,807 Main INFO =========================================\n2022-12-06 20:48:43,808 Main INFO Epoch 9 / 40\n2022-12-06 20:48:43,809 Main INFO =========================================\n2022-12-06 20:48:43,810 Main INFO avg_loss: 0.01033033\n2022-12-06 20:48:43,813 Main INFO avg_val_loss: 0.01042659\n2022-12-06 20:48:43,828 Main INFO Save model at Epoch 9\n2022-12-06 20:48:52,369 Main INFO =========================================\n2022-12-06 20:48:52,370 Main INFO Epoch 10 / 40\n2022-12-06 20:48:52,371 Main INFO =========================================\n2022-12-06 20:48:52,373 Main INFO avg_loss: 0.01019723\n2022-12-06 20:48:52,376 Main INFO avg_val_loss: 0.01035437\n2022-12-06 20:48:52,392 Main INFO Save model at Epoch 10\n2022-12-06 20:49:00,949 Main INFO =========================================\n2022-12-06 20:49:00,951 Main INFO Epoch 11 / 40\n2022-12-06 20:49:00,952 Main INFO =========================================\n2022-12-06 20:49:00,953 Main INFO avg_loss: 0.01009158\n2022-12-06 20:49:00,954 Main INFO avg_val_loss: 0.01031287\n2022-12-06 20:49:00,970 Main INFO Save model at Epoch 11\n2022-12-06 20:49:09,288 Main INFO =========================================\n2022-12-06 20:49:09,289 Main INFO Epoch 12 / 40\n2022-12-06 20:49:09,291 Main INFO =========================================\n2022-12-06 20:49:09,292 Main INFO avg_loss: 0.00999171\n2022-12-06 20:49:09,293 Main INFO avg_val_loss: 0.01026753\n2022-12-06 20:49:09,309 Main INFO Save model at Epoch 12\n2022-12-06 20:49:17,880 Main INFO =========================================\n2022-12-06 20:49:17,881 Main INFO Epoch 13 / 40\n2022-12-06 20:49:17,883 Main INFO =========================================\n2022-12-06 20:49:17,884 Main INFO avg_loss: 0.00990401\n2022-12-06 20:49:17,885 Main INFO avg_val_loss: 0.01022940\n2022-12-06 20:49:17,902 Main INFO Save model at Epoch 13\n2022-12-06 20:49:26,407 Main INFO =========================================\n2022-12-06 20:49:26,408 Main INFO Epoch 14 / 40\n2022-12-06 20:49:26,410 Main INFO =========================================\n2022-12-06 20:49:26,411 Main INFO avg_loss: 0.00981926\n2022-12-06 20:49:26,412 Main INFO avg_val_loss: 0.01020470\n2022-12-06 20:49:26,428 Main INFO Save model at Epoch 14\n2022-12-06 20:49:34,915 Main INFO =========================================\n2022-12-06 20:49:34,916 Main INFO Epoch 15 / 40\n2022-12-06 20:49:34,918 Main INFO =========================================\n2022-12-06 20:49:34,919 Main INFO avg_loss: 0.00974381\n2022-12-06 20:49:34,920 Main INFO avg_val_loss: 0.01018317\n2022-12-06 20:49:34,937 Main INFO Save model at Epoch 15\n2022-12-06 20:49:43,206 Main INFO =========================================\n2022-12-06 20:49:43,207 Main INFO Epoch 16 / 40\n2022-12-06 20:49:43,207 Main INFO =========================================\n2022-12-06 20:49:43,209 Main INFO avg_loss: 0.00967006\n2022-12-06 20:49:43,211 Main INFO avg_val_loss: 0.01014943\n2022-12-06 20:49:43,229 Main INFO Save model at Epoch 16\n2022-12-06 20:51:51,151 Main INFO =========================================\n2022-12-06 20:51:51,152 Main INFO Epoch 31 / 40\n2022-12-06 20:51:51,154 Main INFO =========================================\n2022-12-06 20:51:51,155 Main INFO avg_loss: 0.00909592\n2022-12-06 20:51:51,156 Main INFO avg_val_loss: 0.01002217\n2022-12-06 20:51:51,171 Main INFO Save model at Epoch 31\n2022-12-06 20:52:00,034 Main INFO =========================================\n2022-12-06 20:52:00,036 Main INFO Epoch 32 / 40\n2022-12-06 20:52:00,037 Main INFO =========================================\n2022-12-06 20:52:00,038 Main INFO avg_loss: 0.00908148\n2022-12-06 20:52:00,039 Main INFO avg_val_loss: 0.01002420\n2022-12-06 20:52:08,531 Main INFO =========================================\n2022-12-06 20:52:08,532 Main INFO Epoch 33 / 40\n2022-12-06 20:52:08,534 Main INFO =========================================\n2022-12-06 20:52:08,536 Main INFO avg_loss: 0.00906681\n2022-12-06 20:52:08,537 Main INFO avg_val_loss: 0.01002385\n2022-12-06 20:52:17,216 Main INFO =========================================\n2022-12-06 20:52:17,217 Main INFO Epoch 34 / 40\n2022-12-06 20:52:17,220 Main INFO =========================================\n2022-12-06 20:52:17,220 Main INFO avg_loss: 0.00905902\n2022-12-06 20:52:17,222 Main INFO avg_val_loss: 0.01001939\n2022-12-06 20:52:17,235 Main INFO Save model at Epoch 34\n2022-12-06 20:52:25,726 Main INFO =========================================\n2022-12-06 20:52:25,727 Main INFO Epoch 35 / 40\n2022-12-06 20:52:25,728 Main INFO =========================================\n2022-12-06 20:52:25,729 Main INFO avg_loss: 0.00904869\n2022-12-06 20:52:25,730 Main INFO avg_val_loss: 0.01001255\n2022-12-06 20:52:25,743 Main INFO Save model at Epoch 35\n2022-12-06 20:52:34,216 Main INFO =========================================\n2022-12-06 20:52:34,217 Main INFO Epoch 36 / 40\n2022-12-06 20:52:34,219 Main INFO =========================================\n2022-12-06 20:52:34,220 Main INFO avg_loss: 0.00903591\n2022-12-06 20:52:34,222 Main INFO avg_val_loss: 0.01001407\n2022-12-06 20:52:43,114 Main INFO =========================================\n2022-12-06 20:52:43,115 Main INFO Epoch 37 / 40\n2022-12-06 20:52:43,116 Main INFO =========================================\n2022-12-06 20:52:43,117 Main INFO avg_loss: 0.00902895\n2022-12-06 20:52:43,119 Main INFO avg_val_loss: 0.01001364\n2022-12-06 20:52:51,661 Main INFO =========================================\n2022-12-06 20:52:51,662 Main INFO Epoch 38 / 40\n2022-12-06 20:52:51,664 Main INFO =========================================\n2022-12-06 20:52:51,665 Main INFO avg_loss: 0.00902720\n2022-12-06 20:52:51,666 Main INFO avg_val_loss: 0.01001481\n2022-12-06 20:52:59,947 Main INFO =========================================\n2022-12-06 20:52:59,948 Main INFO Epoch 39 / 40\n2022-12-06 20:52:59,949 Main INFO =========================================\n2022-12-06 20:52:59,951 Main INFO avg_loss: 0.00902859\n2022-12-06 20:52:59,954 Main INFO avg_val_loss: 0.01001159\n2022-12-06 20:52:59,969 Main INFO Save model at Epoch 39\n2022-12-06 20:53:08,474 Main INFO =========================================\n2022-12-06 20:53:08,476 Main INFO Epoch 40 / 40\n2022-12-06 20:53:08,477 Main INFO =========================================\n2022-12-06 20:53:08,478 Main INFO avg_loss: 0.00902347\n2022-12-06 20:53:08,480 Main INFO avg_val_loss: 0.01001165\n2022-12-06 20:53:09,968 Main INFO Best Validation Loss: 0.01001159\n2022-12-06 20:53:10,117 Main INFO Fold 5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Total time: 05:43 <p>"},"metadata":{}},{"name":"stdout","text":"2022-12-06 20:53:19,034 Main INFO =========================================\n2022-12-06 20:53:19,035 Main INFO Epoch 1 / 40\n2022-12-06 20:53:19,038 Main INFO =========================================\n2022-12-06 20:53:19,038 Main INFO avg_loss: 0.02453817\n2022-12-06 20:53:19,040 Main INFO avg_val_loss: 0.01293391\n2022-12-06 20:53:19,051 Main INFO Save model at Epoch 1\n2022-12-06 20:53:27,581 Main INFO =========================================\n2022-12-06 20:53:27,582 Main INFO Epoch 2 / 40\n2022-12-06 20:53:27,583 Main INFO =========================================\n2022-12-06 20:53:27,584 Main INFO avg_loss: 0.01281094\n2022-12-06 20:53:27,586 Main INFO avg_val_loss: 0.01189603\n2022-12-06 20:53:27,599 Main INFO Save model at Epoch 2\n2022-12-06 20:53:36,057 Main INFO =========================================\n2022-12-06 20:53:36,058 Main INFO Epoch 3 / 40\n2022-12-06 20:53:36,060 Main INFO =========================================\n2022-12-06 20:53:36,062 Main INFO avg_loss: 0.01194750\n2022-12-06 20:53:36,062 Main INFO avg_val_loss: 0.01139546\n2022-12-06 20:53:36,080 Main INFO Save model at Epoch 3\n2022-12-06 20:53:44,331 Main INFO =========================================\n2022-12-06 20:53:44,332 Main INFO Epoch 4 / 40\n2022-12-06 20:53:44,333 Main INFO =========================================\n2022-12-06 20:53:44,335 Main INFO avg_loss: 0.01144295\n2022-12-06 20:53:44,336 Main INFO avg_val_loss: 0.01106837\n2022-12-06 20:53:44,353 Main INFO Save model at Epoch 4\n2022-12-06 20:53:53,333 Main INFO =========================================\n2022-12-06 20:53:53,335 Main INFO Epoch 5 / 40\n2022-12-06 20:53:53,335 Main INFO =========================================\n2022-12-06 20:53:53,337 Main INFO avg_loss: 0.01110717\n2022-12-06 20:53:53,338 Main INFO avg_val_loss: 0.01084802\n2022-12-06 20:53:53,351 Main INFO Save model at Epoch 5\n2022-12-06 20:54:01,840 Main INFO =========================================\n2022-12-06 20:54:01,841 Main INFO Epoch 6 / 40\n2022-12-06 20:54:01,843 Main INFO =========================================\n2022-12-06 20:54:01,844 Main INFO avg_loss: 0.01084415\n2022-12-06 20:54:01,845 Main INFO avg_val_loss: 0.01069944\n2022-12-06 20:54:01,859 Main INFO Save model at Epoch 6\n2022-12-06 20:54:10,333 Main INFO =========================================\n2022-12-06 20:54:10,334 Main INFO Epoch 7 / 40\n2022-12-06 20:54:10,335 Main INFO =========================================\n2022-12-06 20:54:10,337 Main INFO avg_loss: 0.01064426\n2022-12-06 20:54:10,338 Main INFO avg_val_loss: 0.01057133\n2022-12-06 20:54:10,351 Main INFO Save model at Epoch 7\n2022-12-06 20:54:19,175 Main INFO =========================================\n2022-12-06 20:54:19,178 Main INFO Epoch 8 / 40\n2022-12-06 20:54:19,180 Main INFO =========================================\n2022-12-06 20:54:19,182 Main INFO avg_loss: 0.01046959\n2022-12-06 20:54:19,184 Main INFO avg_val_loss: 0.01047107\n2022-12-06 20:54:19,204 Main INFO Save model at Epoch 8\n2022-12-06 20:54:27,511 Main INFO =========================================\n2022-12-06 20:54:27,512 Main INFO Epoch 9 / 40\n2022-12-06 20:54:27,514 Main INFO =========================================\n2022-12-06 20:54:27,515 Main INFO avg_loss: 0.01033554\n2022-12-06 20:54:27,516 Main INFO avg_val_loss: 0.01039693\n2022-12-06 20:54:27,528 Main INFO Save model at Epoch 9\n2022-12-06 20:54:36,024 Main INFO =========================================\n2022-12-06 20:54:36,025 Main INFO Epoch 10 / 40\n2022-12-06 20:54:36,028 Main INFO =========================================\n2022-12-06 20:54:36,028 Main INFO avg_loss: 0.01020207\n2022-12-06 20:54:36,030 Main INFO avg_val_loss: 0.01033277\n2022-12-06 20:54:36,043 Main INFO Save model at Epoch 10\n2022-12-06 20:54:44,598 Main INFO =========================================\n2022-12-06 20:54:44,599 Main INFO Epoch 11 / 40\n2022-12-06 20:54:44,600 Main INFO =========================================\n2022-12-06 20:54:44,602 Main INFO avg_loss: 0.01009392\n2022-12-06 20:54:44,603 Main INFO avg_val_loss: 0.01029692\n2022-12-06 20:54:44,616 Main INFO Save model at Epoch 11\n2022-12-06 20:54:53,564 Main INFO =========================================\n2022-12-06 20:54:53,565 Main INFO Epoch 12 / 40\n2022-12-06 20:54:53,567 Main INFO =========================================\n2022-12-06 20:54:53,568 Main INFO avg_loss: 0.00999418\n2022-12-06 20:54:53,569 Main INFO avg_val_loss: 0.01023655\n2022-12-06 20:54:53,586 Main INFO Save model at Epoch 12\n2022-12-06 20:55:01,905 Main INFO =========================================\n2022-12-06 20:55:01,906 Main INFO Epoch 13 / 40\n2022-12-06 20:55:01,906 Main INFO =========================================\n2022-12-06 20:55:01,908 Main INFO avg_loss: 0.00991048\n2022-12-06 20:55:01,909 Main INFO avg_val_loss: 0.01020518\n2022-12-06 20:55:01,924 Main INFO Save model at Epoch 13\n2022-12-06 20:55:10,507 Main INFO =========================================\n2022-12-06 20:55:10,508 Main INFO Epoch 14 / 40\n2022-12-06 20:55:10,509 Main INFO =========================================\n2022-12-06 20:55:10,511 Main INFO avg_loss: 0.00982112\n2022-12-06 20:55:10,514 Main INFO avg_val_loss: 0.01018851\n2022-12-06 20:55:10,528 Main INFO Save model at Epoch 14\n2022-12-06 20:55:18,990 Main INFO =========================================\n2022-12-06 20:55:18,991 Main INFO Epoch 15 / 40\n2022-12-06 20:55:18,992 Main INFO =========================================\n2022-12-06 20:55:18,995 Main INFO avg_loss: 0.00974671\n2022-12-06 20:55:18,996 Main INFO avg_val_loss: 0.01015471\n2022-12-06 20:55:19,012 Main INFO Save model at Epoch 15\n2022-12-06 20:55:27,878 Main INFO =========================================\n2022-12-06 20:55:27,879 Main INFO Epoch 16 / 40\n2022-12-06 20:55:27,879 Main INFO =========================================\n2022-12-06 20:55:27,881 Main INFO avg_loss: 0.00967650\n2022-12-06 20:55:27,882 Main INFO avg_val_loss: 0.01011949\n2022-12-06 20:55:27,897 Main INFO Save model at Epoch 16\n2022-12-06 20:55:36,383 Main INFO =========================================\n2022-12-06 20:55:36,384 Main INFO Epoch 17 / 40\n2022-12-06 20:55:36,386 Main INFO =========================================\n2022-12-06 20:55:36,387 Main INFO avg_loss: 0.00962024\n2022-12-06 20:55:36,388 Main INFO avg_val_loss: 0.01011711\n2022-12-06 20:55:36,404 Main INFO Save model at Epoch 17\n2022-12-06 20:55:44,672 Main INFO =========================================\n2022-12-06 20:55:44,675 Main INFO Epoch 18 / 40\n2022-12-06 20:55:44,677 Main INFO =========================================\n2022-12-06 20:55:44,679 Main INFO avg_loss: 0.00955696\n2022-12-06 20:55:44,680 Main INFO avg_val_loss: 0.01007921\n2022-12-06 20:55:44,702 Main INFO Save model at Epoch 18\n2022-12-06 20:55:53,586 Main INFO =========================================\n2022-12-06 20:55:53,587 Main INFO Epoch 19 / 40\n2022-12-06 20:55:53,588 Main INFO =========================================\n2022-12-06 20:55:53,590 Main INFO avg_loss: 0.00950200\n2022-12-06 20:55:53,591 Main INFO avg_val_loss: 0.01008519\n2022-12-06 20:56:02,161 Main INFO =========================================\n2022-12-06 20:56:02,162 Main INFO Epoch 20 / 40\n2022-12-06 20:56:02,163 Main INFO =========================================\n2022-12-06 20:56:02,165 Main INFO avg_loss: 0.00944804\n2022-12-06 20:56:02,166 Main INFO avg_val_loss: 0.01004457\n2022-12-06 20:56:02,179 Main INFO Save model at Epoch 20\n2022-12-06 20:56:10,811 Main INFO =========================================\n2022-12-06 20:56:10,811 Main INFO Epoch 21 / 40\n2022-12-06 20:56:10,812 Main INFO =========================================\n2022-12-06 20:56:10,814 Main INFO avg_loss: 0.00940323\n2022-12-06 20:56:10,815 Main INFO avg_val_loss: 0.01005181\n2022-12-06 20:56:19,113 Main INFO =========================================\n2022-12-06 20:56:19,114 Main INFO Epoch 22 / 40\n2022-12-06 20:56:19,115 Main INFO =========================================\n2022-12-06 20:56:19,116 Main INFO avg_loss: 0.00935922\n2022-12-06 20:56:19,118 Main INFO avg_val_loss: 0.01004665\n2022-12-06 20:56:28,026 Main INFO =========================================\n2022-12-06 20:56:28,027 Main INFO Epoch 23 / 40\n2022-12-06 20:56:28,029 Main INFO =========================================\n2022-12-06 20:56:28,030 Main INFO avg_loss: 0.00931687\n2022-12-06 20:56:28,030 Main INFO avg_val_loss: 0.01002703\n2022-12-06 20:56:28,046 Main INFO Save model at Epoch 23\n2022-12-06 20:56:36,526 Main INFO =========================================\n2022-12-06 20:56:36,527 Main INFO Epoch 24 / 40\n2022-12-06 20:56:36,530 Main INFO =========================================\n2022-12-06 20:56:36,530 Main INFO avg_loss: 0.00928178\n2022-12-06 20:56:36,532 Main INFO avg_val_loss: 0.01003615\n2022-12-06 20:56:45,046 Main INFO =========================================\n2022-12-06 20:56:45,047 Main INFO Epoch 25 / 40\n2022-12-06 20:56:45,048 Main INFO =========================================\n2022-12-06 20:56:45,049 Main INFO avg_loss: 0.00924711\n2022-12-06 20:56:45,050 Main INFO avg_val_loss: 0.01002133\n2022-12-06 20:56:45,066 Main INFO Save model at Epoch 25\n2022-12-06 20:56:53,563 Main INFO =========================================\n2022-12-06 20:56:53,564 Main INFO Epoch 26 / 40\n2022-12-06 20:56:53,566 Main INFO =========================================\n2022-12-06 20:56:53,567 Main INFO avg_loss: 0.00921360\n2022-12-06 20:56:53,568 Main INFO avg_val_loss: 0.01001058\n2022-12-06 20:56:53,584 Main INFO Save model at Epoch 26\n2022-12-06 20:57:02,451 Main INFO =========================================\n2022-12-06 20:57:02,452 Main INFO Epoch 27 / 40\n2022-12-06 20:57:02,453 Main INFO =========================================\n2022-12-06 20:57:02,454 Main INFO avg_loss: 0.00918380\n2022-12-06 20:57:02,455 Main INFO avg_val_loss: 0.00999464\n2022-12-06 20:57:02,470 Main INFO Save model at Epoch 27\n2022-12-06 20:57:10,973 Main INFO =========================================\n2022-12-06 20:57:10,974 Main INFO Epoch 28 / 40\n2022-12-06 20:57:10,975 Main INFO =========================================\n2022-12-06 20:57:10,977 Main INFO avg_loss: 0.00916481\n2022-12-06 20:57:10,979 Main INFO avg_val_loss: 0.01000172\n2022-12-06 20:57:19,473 Main INFO =========================================\n2022-12-06 20:57:19,474 Main INFO Epoch 29 / 40\n2022-12-06 20:57:19,475 Main INFO =========================================\n2022-12-06 20:57:19,476 Main INFO avg_loss: 0.00914113\n2022-12-06 20:57:19,477 Main INFO avg_val_loss: 0.01000311\n2022-12-06 20:57:28,553 Main INFO =========================================\n2022-12-06 20:57:28,554 Main INFO Epoch 30 / 40\n2022-12-06 20:57:28,554 Main INFO =========================================\n2022-12-06 20:57:28,556 Main INFO avg_loss: 0.00912283\n2022-12-06 20:57:28,557 Main INFO avg_val_loss: 0.00999007\n2022-12-06 20:57:28,572 Main INFO Save model at Epoch 30\n2022-12-06 20:57:36,976 Main INFO =========================================\n2022-12-06 20:57:36,979 Main INFO Epoch 31 / 40\n2022-12-06 20:57:36,981 Main INFO =========================================\n2022-12-06 20:57:36,983 Main INFO avg_loss: 0.00910400\n2022-12-06 20:57:36,985 Main INFO avg_val_loss: 0.00998694\n2022-12-06 20:57:37,006 Main INFO Save model at Epoch 31\n2022-12-06 20:57:45,419 Main INFO =========================================\n2022-12-06 20:57:45,419 Main INFO Epoch 32 / 40\n2022-12-06 20:57:45,420 Main INFO =========================================\n2022-12-06 20:57:45,422 Main INFO avg_loss: 0.00908202\n2022-12-06 20:57:45,423 Main INFO avg_val_loss: 0.00999116\n2022-12-06 20:57:53,909 Main INFO =========================================\n2022-12-06 20:57:53,911 Main INFO Epoch 33 / 40\n2022-12-06 20:57:53,912 Main INFO =========================================\n2022-12-06 20:57:53,913 Main INFO avg_loss: 0.00906721\n2022-12-06 20:57:53,914 Main INFO avg_val_loss: 0.00999444\n2022-12-06 20:58:02,853 Main INFO =========================================\n2022-12-06 20:58:02,854 Main INFO Epoch 34 / 40\n2022-12-06 20:58:02,855 Main INFO =========================================\n2022-12-06 20:58:02,857 Main INFO avg_loss: 0.00906141\n2022-12-06 20:58:02,858 Main INFO avg_val_loss: 0.00998852\n2022-12-06 20:58:11,387 Main INFO =========================================\n2022-12-06 20:58:11,388 Main INFO Epoch 35 / 40\n2022-12-06 20:58:11,389 Main INFO =========================================\n2022-12-06 20:58:11,391 Main INFO avg_loss: 0.00905281\n2022-12-06 20:58:11,392 Main INFO avg_val_loss: 0.00997998\n2022-12-06 20:58:11,410 Main INFO Save model at Epoch 35\n2022-12-06 20:58:19,654 Main INFO =========================================\n2022-12-06 20:58:19,655 Main INFO Epoch 36 / 40\n2022-12-06 20:58:19,655 Main INFO =========================================\n2022-12-06 20:58:19,657 Main INFO avg_loss: 0.00903581\n2022-12-06 20:58:19,658 Main INFO avg_val_loss: 0.00998193\n2022-12-06 20:58:28,175 Main INFO =========================================\n2022-12-06 20:58:28,176 Main INFO Epoch 37 / 40\n2022-12-06 20:58:28,177 Main INFO =========================================\n2022-12-06 20:58:28,178 Main INFO avg_loss: 0.00903523\n2022-12-06 20:58:28,181 Main INFO avg_val_loss: 0.00998135\n2022-12-06 20:58:37,047 Main INFO =========================================\n2022-12-06 20:58:37,048 Main INFO Epoch 38 / 40\n2022-12-06 20:58:37,048 Main INFO =========================================\n2022-12-06 20:58:37,050 Main INFO avg_loss: 0.00903045\n2022-12-06 20:58:37,051 Main INFO avg_val_loss: 0.00998683\n2022-12-06 20:58:45,627 Main INFO =========================================\n2022-12-06 20:58:45,628 Main INFO Epoch 39 / 40\n2022-12-06 20:58:45,630 Main INFO =========================================\n2022-12-06 20:58:45,631 Main INFO avg_loss: 0.00902654\n2022-12-06 20:58:45,633 Main INFO avg_val_loss: 0.00998162\n2022-12-06 20:58:54,098 Main INFO =========================================\n2022-12-06 20:58:54,101 Main INFO Epoch 40 / 40\n2022-12-06 20:58:54,103 Main INFO =========================================\n2022-12-06 20:58:54,105 Main INFO avg_loss: 0.00902127\n2022-12-06 20:58:54,106 Main INFO avg_val_loss: 0.00998134\n2022-12-06 20:58:55,632 Main INFO Best Validation Loss: 0.00997998\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Post process - threshold search -","metadata":{}},{"cell_type":"markdown","source":"Since I used sigmoid for the activation, I've got the 1103 probability output for each data row.\n\nI need to decide threshold for this.There are two ways to deal with this.\n\n- Class-wise threshold search\n  - Takes some time but it's natural.\n- One threshold for all the class\n  - Low cost way.\n\n**UPDATE**\nI will use the first -> second one.","metadata":{}},{"cell_type":"code","source":"def threshold_search(y_pred, y_true):\n    score = []\n    candidates = np.arange(0, 1.0, 0.01)\n    for th in progress_bar(candidates):\n        yp = (y_pred > th).astype(int)\n        score.append(fbeta_score(y_pred=yp, y_true=y_true, beta=2, average=\"samples\"))\n    score = np.array(score)\n    pm = score.argmax()\n    best_th, best_score = candidates[pm], score[pm]\n    return best_th, best_score","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:58:55.798553Z","iopub.execute_input":"2022-12-06T20:58:55.798810Z","iopub.status.idle":"2022-12-06T20:58:55.804669Z","shell.execute_reply.started":"2022-12-06T20:58:55.798766Z","shell.execute_reply":"2022-12-06T20:58:55.803760Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"y_true = np.zeros((train.shape[0], 1103)).astype(int)\nfor i, row in enumerate(y):\n    for idx in row:\n        y_true[i, int(idx)] = 1","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:58:55.805659Z","iopub.execute_input":"2022-12-06T20:58:55.805878Z","iopub.status.idle":"2022-12-06T20:58:56.906065Z","shell.execute_reply.started":"2022-12-06T20:58:55.805826Z","shell.execute_reply":"2022-12-06T20:58:56.905138Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"best_threshold, best_score = threshold_search(valid_preds, y_true)\nbest_score","metadata":{"execution":{"iopub.status.busy":"2022-12-06T20:58:56.907302Z","iopub.execute_input":"2022-12-06T20:58:56.907590Z","iopub.status.idle":"2022-12-06T21:12:22.726733Z","shell.execute_reply.started":"2022-12-06T20:58:56.907543Z","shell.execute_reply":"2022-12-06T21:12:22.726082Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n        <style>\n            /* Turns off some styling */\n            progress {\n                /* gets rid of default border in Firefox and Opera. */\n                border: none;\n                /* Needs to be in here for Safari polyfill so background images work as expected. */\n                background-size: auto;\n            }\n            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n                background: #F44336;\n            }\n        </style>\n      <progress value='100' class='' max='100', style='width:300px; height:20px; vertical-align: middle;'></progress>\n      100.00% [100/100 13:25<00:00]\n    </div>\n    "},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n  'precision', 'predicted', average, warn_for)\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"0.4491267830707251"},"metadata":{}}]},{"cell_type":"markdown","source":"## Prediction for test data","metadata":{}},{"cell_type":"code","source":"test_preds = trainer.predict(test_tensor)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T21:12:22.727898Z","iopub.execute_input":"2022-12-06T21:12:22.728186Z","iopub.status.idle":"2022-12-06T21:12:23.728296Z","shell.execute_reply.started":"2022-12-06T21:12:22.728131Z","shell.execute_reply":"2022-12-06T21:12:23.727338Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"2022-12-06 21:12:23,005 Main INFO [Using bin/2022-12-06-20-30-04/best3.pth] done in 0.2578892707824707 s\n2022-12-06 21:12:23,185 Main INFO [Using bin/2022-12-06-20-30-04/best0.pth] done in 0.178605318069458 s\n2022-12-06 21:12:23,363 Main INFO [Using bin/2022-12-06-20-30-04/best2.pth] done in 0.17663335800170898 s\n2022-12-06 21:12:23,540 Main INFO [Using bin/2022-12-06-20-30-04/best1.pth] done in 0.17629098892211914 s\n2022-12-06 21:12:23,719 Main INFO [Using bin/2022-12-06-20-30-04/best4.pth] done in 0.17759060859680176 s\n","output_type":"stream"}]},{"cell_type":"code","source":"preds = (test_preds > best_threshold).astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-12-06T21:12:23.729708Z","iopub.execute_input":"2022-12-06T21:12:23.729993Z","iopub.status.idle":"2022-12-06T21:12:23.780549Z","shell.execute_reply.started":"2022-12-06T21:12:23.729941Z","shell.execute_reply":"2022-12-06T21:12:23.779899Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"prediction = []\nfor i in range(preds.shape[0]):\n    pred1 = np.argwhere(preds[i] == 1.0).reshape(-1).tolist()\n    pred_str = \" \".join(list(map(str, pred1)))\n    prediction.append(pred_str)\n    \nsample.attribute_ids = prediction\nsample.to_csv(\"submission.csv\", index=False)\nsample.head()","metadata":{"execution":{"iopub.status.busy":"2022-12-06T21:12:23.781982Z","iopub.execute_input":"2022-12-06T21:12:23.782620Z","iopub.status.idle":"2022-12-06T21:12:24.085423Z","shell.execute_reply.started":"2022-12-06T21:12:23.782465Z","shell.execute_reply":"2022-12-06T21:12:24.084477Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                 id                                      attribute_ids\n0  10023b2cc4ed5f68                   121 195 223 343 369 587 766 1059\n1  100fbe75ed8fd887                                    93 231 369 1039\n2  101b627524a04f19                     79 180 420 482 497 498 728 784\n3  10234480c41284c6     13 51 111 147 480 483 725 776 813 830 923 1046\n4  1023b0e2636dcea8  147 189 194 322 477 489 584 612 671 780 813 95...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>attribute_ids</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10023b2cc4ed5f68</td>\n      <td>121 195 223 343 369 587 766 1059</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>100fbe75ed8fd887</td>\n      <td>93 231 369 1039</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>101b627524a04f19</td>\n      <td>79 180 420 482 497 498 728 784</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10234480c41284c6</td>\n      <td>13 51 111 147 480 483 725 776 813 830 923 1046</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1023b0e2636dcea8</td>\n      <td>147 189 194 322 477 489 584 612 671 780 813 95...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}